{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c82a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Imports ready.\n",
      "[Step 1] Dataset loaded: (18240, 21)\n",
      "Columns: ['Year', 'District', 'Mandal', 'Season', 'Soil_Type', 'Soil_pH', 'Organic_Carbon_pct', 'Soil_N_kg_ha', 'Soil_P_kg_ha', 'Soil_K_kg_ha', 'Avg_Temp_C', 'Seasonal_Rainfall_mm', 'Avg_Humidity_pct', 'Water_Source', 'Previous_Crop', 'Primary_Crop', 'Secondary_Crop', 'Suitable_Crops', 'Fertilizer_Plan', 'Irrigation_Plan', 'Market_Price_Index']\n",
      "[Step 2] Parsed multi-labels. #Unique crops: 14 → ['Bengal Gram', 'Chillies', 'Cotton', 'Green Gram', 'Groundnut', 'Maize', 'Millets', 'Paddy', 'Pearl Millet', 'Sesame', 'Sorghum', 'Sunflower', 'Vegetables', 'Watermelon']\n",
      "[Step 2] Built label matrix: (18240, 14) (samples, num_crops)\n",
      "[Step 3] Features prepared: X=(18240, 670), with 670 columns.\n",
      "[Step 4] Feature scaling complete.\n",
      "[Step 5] Train/Test split: train=(14592, 670), test=(3648, 670)\n",
      "[Step 6] Model defined.\n",
      "[Step 7] Training started...\n",
      "[Step 6] Epoch   0 | BCE: nan\n",
      "[Step 6] Epoch  10 | BCE: nan\n",
      "[Step 6] Epoch  20 | BCE: nan\n",
      "[Step 6] Epoch  30 | BCE: nan\n",
      "[Step 6] Epoch  40 | BCE: nan\n",
      "[Step 6] Epoch  50 | BCE: nan\n",
      "[Step 6] Epoch  60 | BCE: nan\n",
      "[Step 6] Epoch  70 | BCE: nan\n",
      "[Step 6] Epoch  79 | BCE: nan\n",
      "[Step 7] Training completed.\n",
      "[Step 8] Subset Accuracy: 0.00% | Micro-P: 0.000  R: 0.000  F1: 0.000\n",
      "[Step 8] Top-3 Hit Rate: 25.16%\n",
      "\n",
      "[Step 9] 10-sample predictions (Top-3):\n",
      "  #01 True=['Pearl Millet', 'Sesame'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #02 True=['Maize', 'Paddy'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #03 True=['Green Gram', 'Paddy'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #04 True=['Groundnut', 'Millets'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #05 True=['Groundnut', 'Paddy'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #06 True=['Maize', 'Paddy'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #07 True=['Pearl Millet', 'Sesame'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #08 True=['Green Gram', 'Paddy'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #09 True=['Chillies', 'Cotton'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "  #10 True=['Groundnut', 'Millets'] | Pred=[('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "\n",
      "[Step 10] Model saved → croprecommender.npz\n",
      "[Step 11] Built District-Season imputation table.\n",
      "[Step 11] Deployment helpers ready.\n",
      "[Step 12] Model reloaded for deployment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 12] Prediction (Top-3): [('Bengal Gram', nan), ('Chillies', nan), ('Cotton', nan)]\n",
      "\n",
      "[Deployment Output]\n",
      "- Bengal Gram (confidence nan)\n",
      "    • Minimal irrigation; drought-tolerant.\n",
      "    • One irrigation at flowering if very dry.\n",
      "    • Avoid heavy irrigation to prevent excess foliage.\n",
      "- Chillies (confidence nan)\n",
      "    • Follow crop-specific recommended irrigation schedule.\n",
      "- Cotton (confidence nan)\n",
      "    • Irrigate ~every 15 days; adjust by weather.\n",
      "    • Critical: squaring, flowering, boll formation.\n",
      "    • Avoid waterlogging (boll rot).\n",
      "\n",
      "✅ ALL DONE: preprocessing → training → evaluation → saving → reload & deploy demo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n",
      "C:\\Users\\charan\\AppData\\Local\\Temp\\ipykernel_59892\\575899501.py:473: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  row_df[col] = 0.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Crop Recommender: NumPy-only, End-to-End\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"[Step 0] Imports ready.\")\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "CSV_PATH = \"apcrop_dataset_realistic.csv\"\n",
    "MODEL_PATH = \"croprecommender.npz\"\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Irrigation guidance (from your list)\n",
    "IRRIGATION_TIPS = {\n",
    "    \"Paddy\": [\n",
    "        \"Daily flooding, maintain 5–10 cm standing water.\",\n",
    "        \"Ensure water at tillering & flowering stages.\",\n",
    "        \"Drain completely 7–10 days before harvest.\"\n",
    "    ],\n",
    "    \"Maize\": [\n",
    "        \"Weekly irrigation; adjust for soil & rainfall.\",\n",
    "        \"Critical at tasseling, silking, grain filling.\",\n",
    "        \"Avoid stress during reproductive phase.\"\n",
    "    ],\n",
    "    \"Groundnut\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: flowering & pegging.\",\n",
    "        \"Maintain moisture during pod development.\"\n",
    "    ],\n",
    "    \"Wheat\": [\n",
    "        \"Irrigate at crown root initiation, jointing, flowering.\",\n",
    "        \"Most critical: ~21 DAS (CRI).\",\n",
    "        \"Avoid waterlogging at tillering.\"\n",
    "    ],\n",
    "    \"Bengal Gram\": [\n",
    "        \"Minimal irrigation; drought-tolerant.\",\n",
    "        \"One irrigation at flowering if very dry.\",\n",
    "        \"Avoid heavy irrigation to prevent excess foliage.\"\n",
    "    ],\n",
    "    \"Sunflower\": [\n",
    "        \"Irrigate ~every 12 days.\",\n",
    "        \"Critical: bud, flowering, seed filling.\",\n",
    "        \"Drip irrigation is effective.\"\n",
    "    ],\n",
    "    \"Castor\": [\n",
    "        \"Irrigate ~every 15 days; hardy crop.\",\n",
    "        \"Critical: branching & spike initiation.\",\n",
    "        \"Too much water → foliage > seeds.\"\n",
    "    ],\n",
    "    \"Bajra\": [\n",
    "        \"Prefer rainfed; drought-tolerant.\",\n",
    "        \"Irrigate at flowering/grain fill if scarce rain.\",\n",
    "        \"Avoid over-irrigation to prevent lodging.\"\n",
    "    ],\n",
    "    \"Linseed\": [\n",
    "        \"Light irrigation at branching & flowering.\",\n",
    "        \"Avoid waterlogging (root diseases).\",\n",
    "        \"1–2 irrigations usually sufficient.\"\n",
    "    ],\n",
    "    \"Mustard\": [\n",
    "        \"Irrigate at branching & pod filling.\",\n",
    "        \"First irrigation ~30–35 DAS.\",\n",
    "        \"Avoid during flowering to prevent flower drop.\"\n",
    "    ],\n",
    "    \"Watermelon\": [\n",
    "        \"Irrigate ~every 7 days, keep soil moisture.\",\n",
    "        \"Critical: flowering & fruit set.\",\n",
    "        \"Reduce irrigation at maturity for sweetness.\"\n",
    "    ],\n",
    "    \"Muskmelon\": [\n",
    "        \"Irrigate ~every 7 days; avoid waterlogging.\",\n",
    "        \"Consistent water for fruit growth & quality.\",\n",
    "        \"Drip helps reduce fungal disease.\"\n",
    "    ],\n",
    "    \"Cowpea\": [\n",
    "        \"Irrigate ~every 10 days (avoid wilting).\",\n",
    "        \"Critical: flowering & pod development.\",\n",
    "        \"Drought-tolerant but timely irrigation boosts yield.\"\n",
    "    ],\n",
    "    \"Cotton\": [\n",
    "        \"Irrigate ~every 15 days; adjust by weather.\",\n",
    "        \"Critical: squaring, flowering, boll formation.\",\n",
    "        \"Avoid waterlogging (boll rot).\"\n",
    "    ],\n",
    "    \"Sugarcane\": [\n",
    "        \"Frequent irrigation—especially in hot, dry periods.\",\n",
    "        \"Maintain moisture up to 120 days (formative).\",\n",
    "        \"Reduce 1–2 months pre-harvest to raise sugar.\"\n",
    "    ],\n",
    "    \"Barley\": [\n",
    "        \"Light irrigations as needed.\",\n",
    "        \"Critical: crown root initiation.\",\n",
    "        \"Sensitive to waterlogging—ensure drainage.\"\n",
    "    ],\n",
    "    \"Lentil\": [\n",
    "        \"Primarily rainfed; minimal irrigation.\",\n",
    "        \"One light irrigation pre-flowering can help.\",\n",
    "        \"Excess water → vegetative growth over seeds.\"\n",
    "    ],\n",
    "    \"Soybean\": [\n",
    "        \"Prefer rainfed; moderate drought tolerance.\",\n",
    "        \"Irrigate at pod filling during dry spells.\",\n",
    "        \"Avoid irrigation at flowering (flower drop).\"\n",
    "    ],\n",
    "    \"Pea\": [\n",
    "        \"Irrigate at flowering & pod filling.\",\n",
    "        \"Initial irrigation post-sowing aids germination.\",\n",
    "        \"Avoid overwatering to prevent root rot.\"\n",
    "    ],\n",
    "    \"Vegetables\": [\n",
    "        \"Irrigate every 5–7 days (crop-dependent).\",\n",
    "        \"Drip to target root zone & conserve water.\",\n",
    "        \"Consistent watering prevents cracking/bitterness.\"\n",
    "    ],\n",
    "    \"Jute\": [\n",
    "        \"Keep soil moist throughout growth.\",\n",
    "        \"Frequent light irrigations in hot season.\",\n",
    "        \"Ensure drainage to prevent root decay.\"\n",
    "    ],\n",
    "    \"Oats\": [\n",
    "        \"Irrigate ~every 12 days as needed.\",\n",
    "        \"Critical: tillering & flowering.\",\n",
    "        \"Relatively drought-tolerant but responds to moisture.\"\n",
    "    ],\n",
    "    \"Cucumber\": [\n",
    "        \"Irrigate ~every 7 days; keep moisture uniform.\",\n",
    "        \"Critical during fruit set/development.\",\n",
    "        \"Low water → bitter fruits.\"\n",
    "    ],\n",
    "    \"Sugar Beet\": [\n",
    "        \"Irrigate ~every 10 days; steady moisture for roots.\",\n",
    "        \"Critical: canopy establishment & root bulking.\",\n",
    "        \"Avoid waterlogging (low sugar, root rot).\"\n",
    "    ],\n",
    "    \"Pearl Millet\": [\n",
    "        \"Prefer rainfed; very drought-tolerant.\",\n",
    "        \"If needed, irrigate at flowering.\",\n",
    "        \"Water stress at grain fill reduces yield.\"\n",
    "    ],\n",
    "    \"Cluster Bean\": [\n",
    "        \"Prefer rainfed; suited for arid conditions.\",\n",
    "        \"1–2 light irrigations during long dry spells.\",\n",
    "        \"Over-watering reduces pod formation.\"\n",
    "    ],\n",
    "    \"Sesame\": [\n",
    "        \"Prefer rainfed; high drought tolerance.\",\n",
    "        \"One irrigation at flowering if soil is dry.\",\n",
    "        \"Highly sensitive to waterlogging (root rot).\"\n",
    "    ],\n",
    "    \"Green Gram\": [\n",
    "        \"Prefer rainfed; irrigation increases yield.\",\n",
    "        \"One irrigation at flowering is critical.\",\n",
    "        \"Avoid heavy irrigation (root diseases).\"\n",
    "    ],\n",
    "    \"Millets\": [\n",
    "        \"Generally rainfed; very drought-tolerant.\",\n",
    "        \"Irrigate only at critical stages if very dry.\",\n",
    "        \"Avoid excess water.\"\n",
    "    ],\n",
    "    \"Sorghum\": [\n",
    "        \"Drought-hardy; mostly rainfed.\",\n",
    "        \"Irrigate at booting/flowering if dry.\",\n",
    "        \"Avoid waterlogging.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# STEP 1: Load\n",
    "# -------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"[Step 1] Dataset loaded:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# -------------------------\n",
    "# STEP 2: Parse labels (multi-label from Suitable_Crops)\n",
    "# -------------------------\n",
    "def parse_crops(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    s = str(cell).strip()\n",
    "    try:\n",
    "        # handle strings like [\"Paddy\",\"Maize\"]\n",
    "        parsed = ast.literal_eval(s)\n",
    "        if isinstance(parsed, list):\n",
    "            return [str(x).strip().strip('\"').strip(\"'\") for x in parsed]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback: comma-separated\n",
    "    return [c.strip().strip('\"').strip(\"'\") for c in s.split(\",\") if c.strip()]\n",
    "\n",
    "df[\"Suitable_Crops_List\"] = df[\"Suitable_Crops\"].apply(parse_crops)\n",
    "all_crops = sorted({c for lst in df[\"Suitable_Crops_List\"] for c in lst})\n",
    "crop_to_idx = {c:i for i,c in enumerate(all_crops)}\n",
    "idx_to_crop = {i:c for c,i in crop_to_idx.items()}\n",
    "print(f\"[Step 2] Parsed multi-labels. #Unique crops: {len(all_crops)} → {all_crops}\")\n",
    "\n",
    "def multilabel_to_matrix(lists, mapping):\n",
    "    m = len(lists)\n",
    "    k = len(mapping)\n",
    "    Y = np.zeros((m, k), dtype=np.float32)\n",
    "    for i, lst in enumerate(lists):\n",
    "        for c in lst:\n",
    "            if c in mapping:\n",
    "                Y[i, mapping[c]] = 1.0\n",
    "    return Y\n",
    "\n",
    "Y = multilabel_to_matrix(df[\"Suitable_Crops_List\"], crop_to_idx)\n",
    "print(\"[Step 2] Built label matrix:\", Y.shape, \"(samples, num_crops)\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 3: Build features\n",
    "# -------------------------\n",
    "# columns to drop (labels + plans + text extras not used as raw features)\n",
    "drop_cols = [\n",
    "    \"Suitable_Crops\", \"Suitable_Crops_List\", \"Fertilizer_Plan\", \"Irrigation_Plan\",\n",
    "    \"Primary_Crop\", \"Secondary_Crop\"\n",
    "]\n",
    "Xdf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\").copy()\n",
    "\n",
    "# Identify categorical vs numeric\n",
    "cat_cols = Xdf.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = Xdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# One-hot encode categoricals\n",
    "Xdf = pd.get_dummies(Xdf, columns=cat_cols, drop_first=False)\n",
    "\n",
    "# Fill missing numerics (if any) with column means\n",
    "Xdf = Xdf.fillna(Xdf.mean(numeric_only=True))\n",
    "\n",
    "# Keep feature names\n",
    "feature_names = list(Xdf.columns)\n",
    "X = Xdf.values.astype(np.float32)\n",
    "\n",
    "print(f\"[Step 3] Features prepared: X={X.shape}, with {len(feature_names)} columns.\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 4: Scale numerics (zero-mean, unit-variance)\n",
    "# -------------------------\n",
    "# Compute stats per feature (works for all since one-hots are 0/1—scaling is fine)\n",
    "f_mean = X.mean(axis=0, keepdims=True)\n",
    "f_std = X.std(axis=0, keepdims=True) + 1e-8\n",
    "X = (X - f_mean) / f_std\n",
    "print(\"[Step 4] Feature scaling complete.\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 5: Train/Test split\n",
    "# -------------------------\n",
    "m = X.shape[0]\n",
    "indices = np.arange(m)\n",
    "np.random.shuffle(indices)\n",
    "split = int(0.8 * m)\n",
    "train_idx, test_idx = indices[:split], indices[split:]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "print(f\"[Step 5] Train/Test split: train={X_train.shape}, test={X_test.shape}\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 6: NumPy MLP (from scratch)\n",
    "# -------------------------\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def bce_loss(y_true, y_pred, eps=1e-8):\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "class NumpyMLP:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=0.01, l2=1e-4, clip=1.0):\n",
    "        self.lr = lr\n",
    "        self.l2 = l2\n",
    "        self.clip = clip\n",
    "        # Xavier init\n",
    "        self.W1 = np.random.randn(input_dim, hidden_dim) / np.sqrt(input_dim)\n",
    "        self.b1 = np.zeros((1, hidden_dim))\n",
    "        self.W2 = np.random.randn(hidden_dim, output_dim) / np.sqrt(hidden_dim)\n",
    "        self.b2 = np.zeros((1, output_dim))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.Z1 = X @ self.W1 + self.b1\n",
    "        self.A1 = np.tanh(self.Z1)\n",
    "        self.Z2 = self.A1 @ self.W2 + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)  # multi-label probs\n",
    "        return self.A2\n",
    "\n",
    "    def backward(self, X, y_true, y_pred):\n",
    "        m = X.shape[0]\n",
    "        # dL/dZ2 for BCE with sigmoid\n",
    "        dZ2 = (y_pred - y_true) / m\n",
    "        dW2 = self.A1.T @ dZ2 + self.l2 * self.W2\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "        dA1 = dZ2 @ self.W2.T\n",
    "        dZ1 = dA1 * (1 - np.tanh(self.Z1) ** 2)\n",
    "        dW1 = X.T @ dZ1 + self.l2 * self.W1\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient clipping\n",
    "        for g in [dW1, db1, dW2, db2]:\n",
    "            np.clip(g, -self.clip, self.clip, out=g)\n",
    "\n",
    "        # Update\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def fit(self, X, y, epochs=80, batch_size=256, verbose=True):\n",
    "        n = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            # shuffle\n",
    "            idx = np.random.permutation(n)\n",
    "            X_shuf, y_shuf = X[idx], y[idx]\n",
    "            # mini-batch\n",
    "            for start in range(0, n, batch_size):\n",
    "                end = start + batch_size\n",
    "                xb = X_shuf[start:end]\n",
    "                yb = y_shuf[start:end]\n",
    "                probs = self.forward(xb)\n",
    "                self.backward(xb, yb, probs)\n",
    "            # report\n",
    "            if verbose and (epoch % 10 == 0 or epoch == epochs - 1):\n",
    "                p = self.forward(X)\n",
    "                loss = bce_loss(y, p)\n",
    "                print(f\"[Step 6] Epoch {epoch:3d} | BCE: {loss:.4f}\")\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "print(\"[Step 6] Model defined.\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 7: Train\n",
    "# -------------------------\n",
    "input_dim  = X_train.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = Y_train.shape[1]\n",
    "\n",
    "model = NumpyMLP(input_dim, hidden_dim, output_dim, lr=0.01, l2=1e-4, clip=1.0)\n",
    "print(\"[Step 7] Training started...\")\n",
    "model.fit(X_train, Y_train, epochs=80, batch_size=256, verbose=True)\n",
    "print(\"[Step 7] Training completed.\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 8: Evaluate\n",
    "# -------------------------\n",
    "def metrics(y_true, y_prob, thresh=0.5):\n",
    "    y_pred = (y_prob >= thresh).astype(np.float32)\n",
    "    # Subset accuracy (exact match)\n",
    "    subset_acc = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    # Micro precision/recall/F1\n",
    "    tp = (y_true * y_pred).sum()\n",
    "    fp = ((1 - y_true) * y_pred).sum()\n",
    "    fn = (y_true * (1 - y_pred)).sum()\n",
    "    prec = tp / (tp + fp + 1e-8)\n",
    "    rec  = tp / (tp + fn + 1e-8)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "    return subset_acc, prec, rec, f1\n",
    "\n",
    "probs_test = model.predict_proba(X_test)\n",
    "subset_acc, prec, rec, f1 = metrics(Y_test, probs_test, thresh=0.5)\n",
    "print(f\"[Step 8] Subset Accuracy: {subset_acc*100:.2f}% | Micro-P: {prec:.3f}  R: {rec:.3f}  F1: {f1:.3f}\")\n",
    "\n",
    "# Top-3 hit rate: whether any true label is in top-3 predictions\n",
    "def topk_hit_rate(y_true, y_prob, k=3):\n",
    "    topk = np.argsort(-y_prob, axis=1)[:, :k]\n",
    "    hits = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        true_labels = np.where(y_true[i] == 1)[0]\n",
    "        if len(set(true_labels).intersection(set(topk[i]))) > 0:\n",
    "            hits += 1\n",
    "    return hits / y_true.shape[0]\n",
    "\n",
    "hit3 = topk_hit_rate(Y_test, probs_test, k=3)\n",
    "print(f\"[Step 8] Top-3 Hit Rate: {hit3*100:.2f}%\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 9: Test on 10 samples\n",
    "# -------------------------\n",
    "sample_idx = np.random.choice(X_test.shape[0], min(10, X_test.shape[0]), replace=False)\n",
    "print(\"\\n[Step 9] 10-sample predictions (Top-3):\")\n",
    "for i, idx in enumerate(sample_idx, 1):\n",
    "    p = probs_test[idx]\n",
    "    top3 = np.argsort(-p)[:3]\n",
    "    recs = [(idx_to_crop[j], float(p[j])) for j in top3]\n",
    "    true = [idx_to_crop[j] for j in np.where(Y_test[idx]==1)[0]]\n",
    "    print(f\"  #{i:02d} True={true} | Pred={[(c, round(s,3)) for c,s in recs]}\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 10: Save model\n",
    "# -------------------------\n",
    "np.savez(\n",
    "    MODEL_PATH,\n",
    "    W1=model.W1, b1=model.b1, W2=model.W2, b2=model.b2,\n",
    "    f_mean=f_mean, f_std=f_std,\n",
    "    feature_names=np.array(feature_names, dtype=object),\n",
    "    classes=np.array(all_crops, dtype=object),\n",
    "    random_seed=np.array([RANDOM_SEED])\n",
    ")\n",
    "print(f\"\\n[Step 10] Model saved → {MODEL_PATH}\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 11: Deployment helpers\n",
    "# -------------------------\n",
    "# Build district-season averages for imputing when soil test is missing\n",
    "use_cols = [\"Soil_pH\",\"Organic_Carbon_pct\",\"Soil_N_kg_ha\",\"Soil_P_kg_ha\",\"Soil_K_kg_ha\",\n",
    "            \"Avg_Temp_C\",\"Seasonal_Rainfall_mm\",\"Avg_Humidity_pct\"]\n",
    "for c in use_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = np.nan\n",
    "\n",
    "group_means = df.groupby([\"District\",\"Season\"])[use_cols].mean().reset_index()\n",
    "print(\"[Step 11] Built District-Season imputation table.\")\n",
    "\n",
    "# One-hot templates for categorical fields from training\n",
    "# (We will rebuild a single-row DataFrame and align columns to training `feature_names`.)\n",
    "def build_feature_row(district, mandal, season, soil_type, water_source,\n",
    "                      prev_crop, year,\n",
    "                      soil_vals=None):\n",
    "    \"\"\"\n",
    "    soil_vals: dict or None\n",
    "        Keys can be any of use_cols above. Missing keys will be imputed from group mean.\n",
    "    \"\"\"\n",
    "    row = {\n",
    "        \"Year\": year,\n",
    "        \"Soil_pH\": np.nan,\n",
    "        \"Organic_Carbon_pct\": np.nan,\n",
    "        \"Soil_N_kg_ha\": np.nan,\n",
    "        \"Soil_P_kg_ha\": np.nan,\n",
    "        \"Soil_K_kg_ha\": np.nan,\n",
    "        \"Avg_Temp_C\": np.nan,\n",
    "        \"Seasonal_Rainfall_mm\": np.nan,\n",
    "        \"Avg_Humidity_pct\": np.nan,\n",
    "        \"District\": district,\n",
    "        \"Mandal\": mandal,\n",
    "        \"Season\": season,\n",
    "        \"Soil_Type\": soil_type,\n",
    "        \"Water_Source\": water_source,\n",
    "        \"Previous_Crop\": prev_crop\n",
    "    }\n",
    "    # fill soil vals if provided\n",
    "    if soil_vals:\n",
    "        for k,v in soil_vals.items():\n",
    "            if k in row:\n",
    "                row[k] = v\n",
    "\n",
    "    # Impute missing numeric using District-Season means\n",
    "    mask = (group_means[\"District\"] == district) & (group_means[\"Season\"] == season)\n",
    "    if mask.any():\n",
    "        g = group_means.loc[mask].iloc[0]\n",
    "        for k in use_cols:\n",
    "            if pd.isna(row.get(k, np.nan)):\n",
    "                row[k] = g.get(k, np.nan)\n",
    "    # Fallback: global mean\n",
    "    for k in use_cols:\n",
    "        if pd.isna(row.get(k, np.nan)):\n",
    "            row[k] = float(df[k].mean())\n",
    "\n",
    "    # Build DataFrame\n",
    "    row_df = pd.DataFrame([row])\n",
    "\n",
    "    # One-hot like training\n",
    "    row_df = pd.get_dummies(row_df, columns=[\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\"Water_Source\",\"Previous_Crop\"], drop_first=False)\n",
    "\n",
    "    # Align to training columns (missing cols -> 0)\n",
    "    for col in feature_names:\n",
    "        if col not in row_df.columns:\n",
    "            row_df[col] = 0.0\n",
    "    # Extra columns in row_df but not in training are dropped\n",
    "    row_df = row_df[feature_names]\n",
    "\n",
    "    # Scale\n",
    "    X_row = row_df.values.astype(np.float32)\n",
    "    X_row = (X_row - f_mean) / f_std\n",
    "    return X_row\n",
    "\n",
    "def load_model(path=MODEL_PATH):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    mdl = {\n",
    "        \"W1\": data[\"W1\"], \"b1\": data[\"b1\"],\n",
    "        \"W2\": data[\"W2\"], \"b2\": data[\"b2\"],\n",
    "        \"f_mean\": data[\"f_mean\"], \"f_std\": data[\"f_std\"],\n",
    "        \"feature_names\": list(data[\"feature_names\"]),\n",
    "        \"classes\": list(data[\"classes\"])\n",
    "    }\n",
    "    return mdl\n",
    "\n",
    "def predict_with_loaded(X_row, mdl, top_n=3):\n",
    "    # forward pass\n",
    "    Z1 = X_row @ mdl[\"W1\"] + mdl[\"b1\"]\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = A1 @ mdl[\"W2\"] + mdl[\"b2\"]\n",
    "    probs = 1.0/(1.0 + np.exp(-Z2))\n",
    "    p = probs.ravel()\n",
    "    top_idx = np.argsort(-p)[:top_n]\n",
    "    return [(mdl[\"classes\"][i], float(p[i])) for i in top_idx]\n",
    "\n",
    "print(\"[Step 11] Deployment helpers ready.\")\n",
    "\n",
    "# -------------------------\n",
    "# STEP 12: Quick deployment demo (no soil test → impute)\n",
    "# -------------------------\n",
    "mdl = load_model(MODEL_PATH)\n",
    "print(\"[Step 12] Model reloaded for deployment.\")\n",
    "\n",
    "# Example usage:\n",
    "example_X = build_feature_row(\n",
    "    district=\"Srikakulam\",\n",
    "    mandal=\"Srikakulam_Mandal_1\",\n",
    "    season=\"Kharif\",\n",
    "    soil_type=\"Mixed\",\n",
    "    water_source=\"Tank\",\n",
    "    prev_crop=\"Paddy\",\n",
    "    year=2019,\n",
    "    soil_vals=None  # None => no soil test provided, will impute by (District, Season)\n",
    ")\n",
    "recs = predict_with_loaded(example_X, mdl, top_n=3)\n",
    "print(\"[Step 12] Prediction (Top-3):\", [(c, round(s,3)) for c,s in recs])\n",
    "\n",
    "# Attach irrigation tips\n",
    "print(\"\\n[Deployment Output]\")\n",
    "for crop, conf in recs:\n",
    "    tips = IRRIGATION_TIPS.get(crop, [\"Follow crop-specific recommended irrigation schedule.\"])\n",
    "    print(f\"- {crop} (confidence {conf:.2f})\")\n",
    "    for t in tips[:3]:\n",
    "        print(f\"    • {t}\")\n",
    "\n",
    "print(\"\\n✅ ALL DONE: preprocessing → training → evaluation → saving → reload & deploy demo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a8e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Imports ready.\n",
      "[Step 1] Dataset loaded: shape=(18240, 21)\n",
      "Columns: ['Year', 'District', 'Mandal', 'Season', 'Soil_Type', 'Soil_pH', 'Organic_Carbon_pct', 'Soil_N_kg_ha', 'Soil_P_kg_ha', 'Soil_K_kg_ha', 'Avg_Temp_C', 'Seasonal_Rainfall_mm', 'Avg_Humidity_pct', 'Water_Source', 'Previous_Crop', 'Primary_Crop', 'Secondary_Crop', 'Suitable_Crops', 'Fertilizer_Plan', 'Irrigation_Plan', 'Market_Price_Index']\n",
      "[Step 2] Crops detected: 14 -> ['Bengal Gram', 'Chillies', 'Cotton', 'Green Gram', 'Groundnut', 'Maize', 'Millets', 'Paddy', 'Pearl Millet', 'Sesame', 'Sorghum', 'Sunflower', 'Vegetables', 'Watermelon']\n",
      "[Step 3] Missing numeric values imputed (district-season aware).\n",
      "[Step 4] Features prepared: X=(18240, 669), y=(18240,), classes=8\n",
      "[Step 5] Model trained (Hybrid Naive Bayes from scratch) ✅\n",
      "[Step 6] Holdout 20% → Acc=1.000 | Macro-F1=1.000 | Top-3 Hit=1.000\n",
      "[Step 6] 5-fold CV → Acc=1.000 | Macro-F1=1.000 | Top-3 Hit=1.000\n",
      "[Step 7] Saved → croprecommender.npz, encoders.pkl, feature_cols.json ✅\n",
      "\n",
      "[Step 8] Demo: NO soil test input →\n",
      "  - Paddy: 1.000\n",
      "     • Daily flooding, maintain 5–10 cm standing water.\n",
      "     • Ensure water at tillering and flowering.\n",
      "  - Bengal Gram: 0.000\n",
      "     • Minimal irrigation; drought-tolerant.\n",
      "     • One light irrigation at flowering if very dry.\n",
      "  - Cotton: 0.000\n",
      "     • Irrigate ~every 15 days; adjust by weather.\n",
      "     • Critical: squaring, flowering, boll formation.\n",
      "\n",
      "[Step 8] Demo: WITH soil test input →\n",
      "  - Paddy: 1.000\n",
      "     • Daily flooding, maintain 5–10 cm standing water.\n",
      "     • Ensure water at tillering and flowering.\n",
      "  - Bengal Gram: 0.000\n",
      "     • Minimal irrigation; drought-tolerant.\n",
      "     • One light irrigation at flowering if very dry.\n",
      "  - Cotton: 0.000\n",
      "     • Irrigate ~every 15 days; adjust by weather.\n",
      "     • Critical: squaring, flowering, boll formation.\n",
      "\n",
      "✅ DONE: training → evaluation → saved model → deploy helpers ready.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Your-Own Crop Recommender (No sklearn, No torch)\n",
    "# End-to-end: preprocessing -> training -> evaluation -> save -> deploy\n",
    "# =========================\n",
    "import json, ast, math, os, random, pickle\n",
    "from collections import defaultdict, Counter\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "CSV_PATH = \"apcrop_dataset_realistic.csv\"   # <-- your file\n",
    "\n",
    "print(\"[Step 0] Imports ready.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# small helpers\n",
    "# ------------------------------------------------------------\n",
    "def try_parse_list(x):\n",
    "    \"\"\"Parse '[\"Paddy\",\"Groundnut\"]' safely into list[str].\"\"\"\n",
    "    if pd.isna(x): return []\n",
    "    if isinstance(x, list): return [str(i).strip() for i in x]\n",
    "    s = str(x).strip()\n",
    "    if not s: return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list): \n",
    "            return [str(i).strip() for i in v]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback: split by comma\n",
    "    s = s.replace(\"[\",\"\").replace(\"]\",\"\").replace('\"','').replace(\"'\",\"\")\n",
    "    return [t.strip() for t in s.split(\",\") if t.strip()]\n",
    "\n",
    "def try_parse_json(x):\n",
    "    if pd.isna(x): return {}\n",
    "    s = str(x).strip()\n",
    "    if not s: return {}\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "def nanmean_safe(series, fallback=None):\n",
    "    v = pd.to_numeric(series, errors=\"coerce\")\n",
    "    m = v.mean()\n",
    "    if pd.isna(m):\n",
    "        return fallback\n",
    "    return m\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) LOAD\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"[Step 1] Dataset loaded: shape={df.shape}\")\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) BASIC NORMALIZATION / PARSE TARGETS\n",
    "# ------------------------------------------------------------\n",
    "expected_cols = [\n",
    "    \"Year\",\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\n",
    "    \"Soil_pH\",\"Organic_Carbon_pct\",\"Soil_N_kg_ha\",\"Soil_P_kg_ha\",\"Soil_K_kg_ha\",\n",
    "    \"Avg_Temp_C\",\"Seasonal_Rainfall_mm\",\"Avg_Humidity_pct\",\n",
    "    \"Water_Source\",\"Previous_Crop\",\"Primary_Crop\",\"Secondary_Crop\",\n",
    "    \"Suitable_Crops\",\"Fertilizer_Plan\",\"Irrigation_Plan\",\"Market_Price_Index\"\n",
    "]\n",
    "for col in expected_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan  # create missing columns\n",
    "\n",
    "# ensure text columns are strings\n",
    "for c in [\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\"Water_Source\",\"Previous_Crop\",\"Primary_Crop\",\"Secondary_Crop\"]:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# parse multi-label and plans\n",
    "df[\"Suitable_Crops_List\"] = df[\"Suitable_Crops\"].apply(try_parse_list)\n",
    "df[\"FertJSON\"] = df[\"Fertilizer_Plan\"].apply(try_parse_json)\n",
    "df[\"IrrJSON\"]  = df[\"Irrigation_Plan\"].apply(try_parse_json)\n",
    "\n",
    "# collect all unique crop names visible in dataset\n",
    "crop_set = set()\n",
    "for col in [\"Primary_Crop\",\"Secondary_Crop\"]:\n",
    "    crop_set.update(df[col].dropna().astype(str).str.strip())\n",
    "for L in df[\"Suitable_Crops_List\"]:\n",
    "    crop_set.update(L)\n",
    "# clean empties\n",
    "crop_set = {c for c in crop_set if c and c.lower()!=\"nan\"}\n",
    "crop_list = sorted(crop_set)\n",
    "print(f\"[Step 2] Crops detected: {len(crop_list)} -> {crop_list}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) IMPUTATION VALUES (District+Season aware)\n",
    "# ------------------------------------------------------------\n",
    "num_cols = [\"Soil_pH\",\"Organic_Carbon_pct\",\"Soil_N_kg_ha\",\"Soil_P_kg_ha\",\"Soil_K_kg_ha\",\n",
    "            \"Avg_Temp_C\",\"Seasonal_Rainfall_mm\",\"Avg_Humidity_pct\",\"Market_Price_Index\"]\n",
    "\n",
    "# seasonal defaults if whole column empty\n",
    "season_defaults = {\n",
    "    \"Kharif\": {\"Avg_Temp_C\": 29.0, \"Seasonal_Rainfall_mm\": 600.0, \"Avg_Humidity_pct\": 78.0},\n",
    "    \"Rabi\":   {\"Avg_Temp_C\": 23.0, \"Seasonal_Rainfall_mm\": 200.0, \"Avg_Humidity_pct\": 65.0},\n",
    "    \"Zaid\":   {\"Avg_Temp_C\": 31.0, \"Seasonal_Rainfall_mm\": 120.0, \"Avg_Humidity_pct\": 70.0},\n",
    "}\n",
    "\n",
    "# compute district-season means\n",
    "group_means = df.groupby([\"District\",\"Season\"])[num_cols].agg(lambda s: pd.to_numeric(s, errors=\"coerce\").mean()).reset_index()\n",
    "\n",
    "def impute_row(row):\n",
    "    d, s = row[\"District\"], row[\"Season\"]\n",
    "    # lookup district-season row\n",
    "    g = group_means[(group_means[\"District\"]==d) & (group_means[\"Season\"]==s)]\n",
    "    for col in num_cols:\n",
    "        if pd.isna(row[col]) or str(row[col]).strip()==\"\":\n",
    "            # district-season mean -> season default -> global mean\n",
    "            val = None\n",
    "            if not g.empty and not pd.isna(g.iloc[0][col]):\n",
    "                val = g.iloc[0][col]\n",
    "            if val is None or pd.isna(val):\n",
    "                if s in season_defaults and col in season_defaults[s]:\n",
    "                    val = season_defaults[s][col]\n",
    "            if val is None or pd.isna(val):\n",
    "                val = nanmean_safe(df[col], 0.0)\n",
    "            row[col] = val\n",
    "    return row\n",
    "\n",
    "df = df.apply(impute_row, axis=1)\n",
    "print(\"[Step 3] Missing numeric values imputed (district-season aware).\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) FEATURE ENGINEERING\n",
    "#     - encode categoricals with a custom OneHot encoder\n",
    "#     - keep numeric as float\n",
    "# ------------------------------------------------------------\n",
    "cat_cols = [\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\"Water_Source\",\"Previous_Crop\"]\n",
    "target_col = \"Primary_Crop\"  # single-label target for training\n",
    "\n",
    "class OneHotEncoderLite:\n",
    "    def __init__(self):\n",
    "        self.cat_maps = {}   # col -> {category: index}\n",
    "        self.col_index_ranges = {}  # col -> (start,end)\n",
    "        self.n_features_ = 0\n",
    "    \n",
    "    def fit(self, frame, cat_cols):\n",
    "        start = 0\n",
    "        for col in cat_cols:\n",
    "            uniq = sorted({str(x) for x in frame[col].fillna(\"NA_VALUE\").astype(str)})\n",
    "            mapping = {u:i for i,u in enumerate(uniq)}\n",
    "            self.cat_maps[col] = mapping\n",
    "            end = start + len(mapping)\n",
    "            self.col_index_ranges[col] = (start, end)\n",
    "            start = end\n",
    "        self.n_features_ = start\n",
    "        return self\n",
    "    \n",
    "    def transform(self, frame):\n",
    "        # build empty array: (n_samples, total_cat_dim)\n",
    "        out = np.zeros((len(frame), self.n_features_), dtype=np.float32)\n",
    "        for col, mapping in self.cat_maps.items():\n",
    "            start, end = self.col_index_ranges[col]\n",
    "            idxs = frame[col].fillna(\"NA_VALUE\").astype(str).map(lambda v: mapping.get(v, None))\n",
    "            for i, idx in enumerate(idxs):\n",
    "                if idx is not None:\n",
    "                    out[i, start+idx] = 1.0\n",
    "        return out\n",
    "\n",
    "# prepare numeric matrix\n",
    "X_num = df[num_cols].astype(float).values.astype(np.float32)\n",
    "\n",
    "# fit onehot\n",
    "ohe = OneHotEncoderLite().fit(df, cat_cols)\n",
    "X_cat = ohe.transform(df)\n",
    "\n",
    "# final features = [numeric | onehot]\n",
    "X = np.concatenate([X_num, X_cat], axis=1)\n",
    "\n",
    "# target encode to integers\n",
    "class LabelEncoderLite:\n",
    "    def __init__(self):\n",
    "        self.class_to_id = {}\n",
    "        self.id_to_class = []\n",
    "    def fit(self, y):\n",
    "        uniq = sorted(set(y))\n",
    "        self.class_to_id = {c:i for i,c in enumerate(uniq)}\n",
    "        self.id_to_class = uniq\n",
    "        return self\n",
    "    def transform(self, y):\n",
    "        return np.array([self.class_to_id[v] for v in y], dtype=np.int64)\n",
    "    def inverse_transform(self, ids):\n",
    "        return [self.id_to_class[i] for i in ids]\n",
    "\n",
    "le_y = LabelEncoderLite().fit(df[target_col].astype(str))\n",
    "y = le_y.transform(df[target_col].astype(str))\n",
    "\n",
    "print(f\"[Step 4] Features prepared: X={X.shape}, y={y.shape}, classes={len(le_y.id_to_class)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) MODEL (from scratch Hybrid Naive Bayes)\n",
    "#    - Gaussian NB on numeric features\n",
    "#    - Categorical NB on one-hot (simple Bernoulli with Laplace smoothing)\n",
    "# ------------------------------------------------------------\n",
    "class HybridNaiveBayes:\n",
    "    def __init__(self, n_num, n_cat, alpha=1.0, var_smoothing=1e-9):\n",
    "        self.n_num = n_num\n",
    "        self.n_cat = n_cat\n",
    "        self.alpha = alpha\n",
    "        self.var_smoothing = var_smoothing\n",
    "        # learned:\n",
    "        self.class_priors = None                  # [K]\n",
    "        self.num_means = None                     # [K, n_num]\n",
    "        self.num_vars = None                      # [K, n_num]\n",
    "        self.cat_feature_pos = None               # [K, n_cat] P(x=1|class)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        K = len(np.unique(y))\n",
    "        n = X.shape[1]\n",
    "        assert n == self.n_num + self.n_cat\n",
    "        X_num = X[:, :self.n_num]\n",
    "        X_cat = X[:, self.n_num:]\n",
    "        self.class_priors = np.zeros(K, dtype=np.float64)\n",
    "        self.num_means = np.zeros((K, self.n_num), dtype=np.float64)\n",
    "        self.num_vars  = np.zeros((K, self.n_num), dtype=np.float64)\n",
    "        self.cat_feature_pos = np.zeros((K, self.n_cat), dtype=np.float64)\n",
    "\n",
    "        for k in range(K):\n",
    "            mask = (y == k)\n",
    "            Xk_num = X_num[mask]\n",
    "            Xk_cat = X_cat[mask]\n",
    "\n",
    "            # priors\n",
    "            self.class_priors[k] = (np.sum(mask) + self.alpha) / (len(y) + K*self.alpha)\n",
    "\n",
    "            # gaussian stats\n",
    "            if Xk_num.shape[0] > 0:\n",
    "                self.num_means[k] = np.mean(Xk_num, axis=0)\n",
    "                # variance with smoothing to avoid zero\n",
    "                self.num_vars[k]  = np.var(Xk_num, axis=0) + self.var_smoothing\n",
    "            else:\n",
    "                self.num_means[k] = 0.0\n",
    "                self.num_vars[k]  = 1.0\n",
    "\n",
    "            # categorical: Bernoulli likelihood with Laplace smoothing\n",
    "            # count ones per feature in class\n",
    "            pos = Xk_cat.sum(axis=0)  # how many ones\n",
    "            total = Xk_cat.shape[0]\n",
    "            self.cat_feature_pos[k] = (pos + self.alpha) / (total + 2*self.alpha) if total>0 else (0.5*np.ones(self.n_cat))\n",
    "        return self\n",
    "\n",
    "    def _log_gaussian_prob(self, X_num, k):\n",
    "        # log N(x|mean,var) across dimensions (sum)\n",
    "        mean_k = self.num_means[k]\n",
    "        var_k  = self.num_vars[k]\n",
    "        return -0.5*(np.log(2*np.pi*var_k).sum() + ((X_num - mean_k)**2/var_k).sum(axis=1))\n",
    "    \n",
    "    def _log_bernoulli_prob(self, X_cat, k):\n",
    "        p = np.clip(self.cat_feature_pos[k], 1e-12, 1-1e-12)\n",
    "        # X in {0,1}, log p^X (1-p)^(1-X) = X*log p + (1-X)*log(1-p)\n",
    "        return (X_cat*np.log(p) + (1-X_cat)*np.log(1-p)).sum(axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_num = X[:, :self.n_num]\n",
    "        X_cat = X[:, self.n_num:]\n",
    "        K = len(self.class_priors)\n",
    "        log_post = []\n",
    "        for k in range(K):\n",
    "            lp = math.log(self.class_priors[k]) \\\n",
    "                 + self._log_gaussian_prob(X_num, k) \\\n",
    "                 + self._log_bernoulli_prob(X_cat, k)\n",
    "            log_post.append(lp)\n",
    "        log_post = np.vstack(log_post).T  # [N,K]\n",
    "        # normalize to probabilities\n",
    "        m = log_post.max(axis=1, keepdims=True)\n",
    "        post = np.exp(log_post - m)\n",
    "        post = post / post.sum(axis=1, keepdims=True)\n",
    "        return post\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)\n",
    "\n",
    "# split (holdout) — we’ll also do 5-fold CV later\n",
    "idx = np.arange(len(df))\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.8*len(idx))\n",
    "train_idx, test_idx = idx[:split], idx[split:]\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test,  y_test  = X[test_idx],  y[test_idx]\n",
    "\n",
    "model = HybridNaiveBayes(n_num=X_num.shape[1], n_cat=X_cat.shape[1], alpha=1.0, var_smoothing=1e-6)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"[Step 5] Model trained (Hybrid Naive Bayes from scratch) ✅\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) EVALUATION\n",
    "# ------------------------------------------------------------\n",
    "def metrics_basic(y_true, y_pred, proba=None, top_k=3):\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    # macro precision/recall/f1\n",
    "    K = len(set(y_true) | set(y_pred))\n",
    "    precs, recs, f1s = [], [], []\n",
    "    for k in range(K):\n",
    "        tp = np.sum((y_true==k) & (y_pred==k))\n",
    "        fp = np.sum((y_true!=k) & (y_pred==k))\n",
    "        fn = np.sum((y_true==k) & (y_pred!=k))\n",
    "        precision = tp / (tp+fp) if (tp+fp)>0 else 0.0\n",
    "        recall    = tp / (tp+fn) if (tp+fn)>0 else 0.0\n",
    "        f1 = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0.0\n",
    "        precs.append(precision); recs.append(recall); f1s.append(f1)\n",
    "    macro_p, macro_r, macro_f1 = np.mean(precs), np.mean(recs), np.mean(f1s)\n",
    "\n",
    "    topk = None\n",
    "    if proba is not None:\n",
    "        topk_preds = np.argsort(-proba, axis=1)[:, :top_k]\n",
    "        hits = [(y_true[i] in topk_preds[i]) for i in range(len(y_true))]\n",
    "        topk = np.mean(hits)\n",
    "    return acc, macro_p, macro_r, macro_f1, topk\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "proba_test  = model.predict_proba(X_test)\n",
    "acc, mp, mr, mf1, top3 = metrics_basic(y_test, y_pred_test, proba_test, top_k=3)\n",
    "print(f\"[Step 6] Holdout 20% → Acc={acc:.3f} | Macro-F1={mf1:.3f} | Top-3 Hit={top3:.3f}\")\n",
    "\n",
    "# 5-fold CV for robustness\n",
    "def kfold_eval(X, y, k=5):\n",
    "    N = len(y)\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "    folds = np.array_split(idx, k)\n",
    "    accs, f1s, top3s = [], [], []\n",
    "    for i in range(k):\n",
    "        test_i = folds[i]\n",
    "        train_i = np.hstack([folds[j] for j in range(k) if j!=i])\n",
    "        m = HybridNaiveBayes(n_num=X_num.shape[1], n_cat=X_cat.shape[1], alpha=1.0, var_smoothing=1e-6)\n",
    "        m.fit(X[train_i], y[train_i])\n",
    "        yp = m.predict(X[test_i])\n",
    "        pp = m.predict_proba(X[test_i])\n",
    "        a,_,_,f1,t3 = metrics_basic(y[test_i], yp, pp, top_k=3)\n",
    "        accs.append(a); f1s.append(f1); top3s.append(t3)\n",
    "    return np.mean(accs), np.mean(f1s), np.mean(top3s)\n",
    "\n",
    "cv_acc, cv_f1, cv_top3 = kfold_eval(X, y, k=5)\n",
    "print(f\"[Step 6] 5-fold CV → Acc={cv_acc:.3f} | Macro-F1={cv_f1:.3f} | Top-3 Hit={cv_top3:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) SAVE ARTIFACTS\n",
    "# ------------------------------------------------------------\n",
    "ART_DIR = \".\"\n",
    "np.savez(os.path.join(ART_DIR,\"croprecommender.npz\"),\n",
    "         class_priors=model.class_priors,\n",
    "         num_means=model.num_means,\n",
    "         num_vars=model.num_vars,\n",
    "         cat_feature_pos=model.cat_feature_pos,\n",
    "         n_num=model.n_num, n_cat=model.n_cat)\n",
    "\n",
    "with open(os.path.join(ART_DIR,\"encoders.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\"ohe\":ohe, \"le_y\":le_y, \"num_cols\":num_cols, \"cat_cols\":cat_cols}, f)\n",
    "\n",
    "with open(os.path.join(ART_DIR,\"feature_cols.json\"), \"w\") as f:\n",
    "    json.dump({\"num_cols\":num_cols, \"cat_cols\":cat_cols}, f, indent=2)\n",
    "\n",
    "print(\"[Step 7] Saved → croprecommender.npz, encoders.pkl, feature_cols.json ✅\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) IRRIGATION SUGGESTIONS (your mapping)\n",
    "# ------------------------------------------------------------\n",
    "IRRIGATION_TIPS = {\n",
    "    \"Paddy\": [\n",
    "        \"Daily flooding, maintain 5–10 cm standing water.\",\n",
    "        \"Ensure water at tillering and flowering.\",\n",
    "        \"Drain completely 7–10 days before harvest.\"\n",
    "    ],\n",
    "    \"Maize\": [\n",
    "        \"Irrigate weekly; adjust to rainfall & soil.\",\n",
    "        \"Critical: tasseling, silking, grain filling.\",\n",
    "        \"Avoid stress in reproductive phase.\"\n",
    "    ],\n",
    "    \"Groundnut\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: flowering & pegging stages.\",\n",
    "        \"Keep moisture during pod development.\"\n",
    "    ],\n",
    "    \"Wheat\": [\n",
    "        \"Irrigate at CRI, jointing, flowering.\",\n",
    "        \"CRI (≈21 DAS) is most critical.\",\n",
    "        \"Avoid waterlogging.\"\n",
    "    ],\n",
    "    \"Bengal Gram\": [\n",
    "        \"Minimal irrigation; drought-tolerant.\",\n",
    "        \"One light irrigation at flowering if very dry.\",\n",
    "        \"Avoid heavy irrigation.\"\n",
    "    ],\n",
    "    \"Sunflower\": [\n",
    "        \"Irrigate ~every 12 days.\",\n",
    "        \"Critical: bud, flowering, seed filling.\",\n",
    "        \"Drip works very well.\"\n",
    "    ],\n",
    "    \"Castor\": [\n",
    "        \"Irrigate ~every 15 days.\",\n",
    "        \"Provide at branching & spike initiation.\",\n",
    "        \"Too much water → foliage, fewer seeds.\"\n",
    "    ],\n",
    "    \"Bajra\": [\n",
    "        \"Prefer rainfed; drought-tolerant.\",\n",
    "        \"If needed, irrigate at flowering & grain filling.\",\n",
    "        \"Avoid over-irrigation (lodging risk).\"\n",
    "    ],\n",
    "    \"Linseed\": [\n",
    "        \"Light irrigation at branching & flowering.\",\n",
    "        \"Never waterlog; highly susceptible.\",\n",
    "        \"1–2 irrigations often enough.\"\n",
    "    ],\n",
    "    \"Mustard\": [\n",
    "        \"Irrigate at branching & pod filling.\",\n",
    "        \"First irrigation 30–35 DAS.\",\n",
    "        \"Avoid watering during flowering.\"\n",
    "    ],\n",
    "    \"Watermelon\": [\n",
    "        \"Irrigate ~every 7 days; keep moisture even.\",\n",
    "        \"Avoid stress at flowering & fruit set.\",\n",
    "        \"Reduce water near maturity for sweetness.\"\n",
    "    ],\n",
    "    \"Muskmelon\": [\n",
    "        \"Irrigate ~every 7 days, avoid waterlogging.\",\n",
    "        \"Consistent water for fruit growth & quality.\",\n",
    "        \"Drip reduces fungal risk.\"\n",
    "    ],\n",
    "    \"Cowpea\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: flowering & pod development.\",\n",
    "        \"Drought tolerant but timely water boosts yield.\"\n",
    "    ],\n",
    "    \"Cotton\": [\n",
    "        \"Irrigate ~every 15 days; adjust by weather.\",\n",
    "        \"Critical: squaring, flowering, boll formation.\",\n",
    "        \"Avoid waterlogging (boll rot).\"\n",
    "    ],\n",
    "    \"Sugarcane\": [\n",
    "        \"Frequent water in hot/dry months.\",\n",
    "        \"Formative stage (to ~120 DAS) needs moisture.\",\n",
    "        \"Reduce 1–2 months pre-harvest.\"\n",
    "    ],\n",
    "    \"Barley\": [\n",
    "        \"Light irrigations as needed.\",\n",
    "        \"CRI is most crucial.\",\n",
    "        \"Sensitive to waterlogging.\"\n",
    "    ],\n",
    "    \"Lentil\": [\n",
    "        \"Mostly rainfed.\",\n",
    "        \"One light irrigation pre-flowering may help.\",\n",
    "        \"Too much water → vegetative growth.\"\n",
    "    ],\n",
    "    \"Soybean\": [\n",
    "        \"Prefer rainfed/moderate drought tolerance.\",\n",
    "        \"Supplement at pod filling if dry.\",\n",
    "        \"Avoid irrigation during flowering.\"\n",
    "    ],\n",
    "    \"Pea\": [\n",
    "        \"Irrigate at flowering & pod filling.\",\n",
    "        \"Initial irrigation helps germination.\",\n",
    "        \"Avoid overwatering (root rot risk).\"\n",
    "    ],\n",
    "    \"Vegetables\": [\n",
    "        \"Irrigate every 5–7 days depending on crop.\",\n",
    "        \"Drip to root-zone conserves water.\",\n",
    "        \"Consistency prevents cracking/bitterness.\"\n",
    "    ],\n",
    "    \"Jute\": [\n",
    "        \"Keep soil moist throughout.\",\n",
    "        \"Frequent light irrigation in hot season.\",\n",
    "        \"Ensure drainage to avoid root decay.\"\n",
    "    ],\n",
    "    \"Oats\": [\n",
    "        \"Irrigate ~every 12 days.\",\n",
    "        \"Critical: tillering & flowering.\",\n",
    "        \"Relatively drought-tolerant.\"\n",
    "    ],\n",
    "    \"Cucumber\": [\n",
    "        \"Irrigate ~every 7 days; uniform moisture.\",\n",
    "        \"Consistent water at fruit set & growth.\",\n",
    "        \"Low water → bitter fruits.\"\n",
    "    ],\n",
    "    \"Sugar Beet\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: canopy establishment, root bulking.\",\n",
    "        \"Avoid waterlogging (low sugar, root rot).\"\n",
    "    ],\n",
    "    \"Pearl Millet\": [\n",
    "        \"Prefer rainfed; very drought-tolerant.\",\n",
    "        \"If needed, irrigate at flowering.\",\n",
    "        \"Water stress at grain filling cuts yield.\"\n",
    "    ],\n",
    "    \"Cluster Bean\": [\n",
    "        \"Prefer rainfed; arid-suited.\",\n",
    "        \"1–2 light irrigations in long dry spells.\",\n",
    "        \"Overwatering reduces pod set.\"\n",
    "    ],\n",
    "    \"Sesame\": [\n",
    "        \"Prefer rainfed; drought-hardy.\",\n",
    "        \"One irrigation at flowering if dry.\",\n",
    "        \"Avoid waterlogging (root rot).\"\n",
    "    ],\n",
    "    \"Green Gram\": [\n",
    "        \"Rainfed OK; one irrigation at flowering.\",\n",
    "        \"Avoid heavy irrigation (root disease risk).\",\n",
    "        \"Irrigation can boost yield modestly.\"\n",
    "    ],\n",
    "    \"Millets\": [\n",
    "        \"Mostly rainfed; high drought tolerance.\",\n",
    "        \"Irrigate only at critical stages if very dry.\",\n",
    "        \"Avoid excessive water.\"\n",
    "    ],\n",
    "    \"Sorghum\": [\n",
    "        \"Mostly rainfed; irrigate if prolonged dry.\",\n",
    "        \"Critical: booting & flowering.\",\n",
    "        \"Avoid waterlogging.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) DEPLOYMENT HELPERS\n",
    "# ------------------------------------------------------------\n",
    "def build_feature_row(input_dict, encoders, ohe, num_cols, cat_cols):\n",
    "    \"\"\"\n",
    "    input_dict keys may include numeric and categorical fields.\n",
    "    Missing numeric are imputed with district-season means (computed earlier) or season defaults.\n",
    "    \"\"\"\n",
    "    # Start with a template row\n",
    "    row = {}\n",
    "    # numeric\n",
    "    for c in num_cols:\n",
    "        row[c] = input_dict.get(c, None)\n",
    "    # categorical\n",
    "    for c in cat_cols:\n",
    "        row[c] = input_dict.get(c, \"NA_VALUE\")\n",
    "\n",
    "    # impute numeric using same logic as training\n",
    "    tmp = pd.DataFrame([row])\n",
    "    # attach District & Season so imputer can work\n",
    "    tmp[\"District\"] = row.get(\"District\", \"NA_VALUE\")\n",
    "    tmp[\"Season\"]   = row.get(\"Season\",   \"Kharif\")\n",
    "\n",
    "    # district-season means lookup\n",
    "    g = group_means[(group_means[\"District\"]==tmp.at[0,\"District\"]) & (group_means[\"Season\"]==tmp.at[0,\"Season\"])]\n",
    "\n",
    "    for col in num_cols:\n",
    "        val = tmp.at[0, col]\n",
    "        if val is None or (isinstance(val,str) and not val.strip()):\n",
    "            # fill\n",
    "            dv = None\n",
    "            if not g.empty and not pd.isna(g.iloc[0][col]):\n",
    "                dv = g.iloc[0][col]\n",
    "            if (dv is None or pd.isna(dv)) and tmp.at[0,\"Season\"] in season_defaults and col in season_defaults[tmp.at[0,\"Season\"]]:\n",
    "                dv = season_defaults[tmp.at[0,\"Season\"]][col]\n",
    "            if dv is None or pd.isna(dv):\n",
    "                dv = nanmean_safe(df[col], 0.0)\n",
    "            tmp.at[0, col] = dv\n",
    "\n",
    "    # numeric block\n",
    "    x_num = tmp[num_cols].astype(float).values.astype(np.float32)\n",
    "    # categorical block via ohe\n",
    "    x_cat = ohe.transform(tmp[cat_cols])\n",
    "    # final vector\n",
    "    x = np.concatenate([x_num, x_cat], axis=1)\n",
    "    return x\n",
    "\n",
    "def predict_topN(input_dict, N=3):\n",
    "    x = build_feature_row(input_dict, encoders=None, ohe=ohe, num_cols=num_cols, cat_cols=cat_cols)\n",
    "    probs = model.predict_proba(x)[0]\n",
    "    top_idx = np.argsort(-probs)[:N]\n",
    "    crops = [le_y.id_to_class[i] for i in top_idx]\n",
    "    confs = [float(probs[i]) for i in top_idx]\n",
    "    tips  = {c: IRRIGATION_TIPS.get(c, [\"Follow crop-specific schedule.\"]) for c in crops}\n",
    "    return list(zip(crops, confs)), tips\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) QUICK DEMO PREDICTION (with/without soil test)\n",
    "#     “Soil test? No” → only district, season, water source are enough.\n",
    "# ------------------------------------------------------------\n",
    "demo_no_soil = {\n",
    "    \"District\": \"Srikakulam\",\n",
    "    \"Season\": \"Kharif\",\n",
    "    \"Water_Source\": \"Tank\",     # choose among: Tank/Canal/Borewell/...\n",
    "    # no soil fields given\n",
    "}\n",
    "demo_with_soil = {\n",
    "    \"District\": \"Srikakulam\",\n",
    "    \"Season\": \"Rabi\",\n",
    "    \"Water_Source\": \"Tank\",\n",
    "    \"Soil_pH\": 6.6,\n",
    "    \"Organic_Carbon_pct\": 0.7,\n",
    "    \"Soil_N_kg_ha\": 200,\n",
    "    \"Soil_P_kg_ha\": 18,\n",
    "    \"Soil_K_kg_ha\": 180,\n",
    "    \"Avg_Temp_C\": 23.0,\n",
    "    \"Seasonal_Rainfall_mm\": 650,\n",
    "    \"Avg_Humidity_pct\": 68,\n",
    "    \"Market_Price_Index\": 0.62\n",
    "}\n",
    "\n",
    "print(\"\\n[Step 8] Demo: NO soil test input →\")\n",
    "preds, tips = predict_topN(demo_no_soil, N=3)\n",
    "for c, p in preds:\n",
    "    print(f\"  - {c}: {p:.3f}\")\n",
    "    for t in tips[c][:2]:\n",
    "        print(\"     •\", t)\n",
    "\n",
    "print(\"\\n[Step 8] Demo: WITH soil test input →\")\n",
    "preds2, tips2 = predict_topN(demo_with_soil, N=3)\n",
    "for c, p in preds2:\n",
    "    print(f\"  - {c}: {p:.3f}\")\n",
    "    for t in tips2[c][:2]:\n",
    "        print(\"     •\", t)\n",
    "\n",
    "print(\"\\n✅ DONE: training → evaluation → saved model → deploy helpers ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beaa5300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RANDOM SAMPLE TESTING ===\n",
      "Sample 1:\n",
      "  Features: [  6.8   0.9 280.   25.  220.   31.  120.   70.    0.9   0.    0.    0.\n",
      "   0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    1.    0.\n",
      "   0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    0. ]\n",
      "  Actual Crop: 7\n",
      "  Predicted Crop: 7\n",
      "----------------------------------------\n",
      "Sample 2:\n",
      "  Features: [  7.4    0.8  220.    18.   260.    23.   200.    65.     0.85   0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     1.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     1.     0.     0.     1.     0.     0.\n",
      "   1.     0.     0.     0.     0.     1.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      "  Actual Crop: 1\n",
      "  Predicted Crop: 1\n",
      "----------------------------------------\n",
      "Sample 3:\n",
      "  Features: [  6.6    0.7  200.    18.   180.    29.   600.    78.     0.75   0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     1.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     1.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     1.     0.\n",
      "   0.     0.     1.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     0.  ]\n",
      "  Actual Crop: 5\n",
      "  Predicted Crop: 5\n",
      "----------------------------------------\n",
      "Sample 4:\n",
      "  Features: [  6.8    0.9  280.    25.   220.    29.   600.    78.     0.75   0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     1.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     1.     0.     0.     0.\n",
      "   0.     1.     0.     0.     0.     1.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      "  Actual Crop: 5\n",
      "  Predicted Crop: 5\n",
      "----------------------------------------\n",
      "Sample 5:\n",
      "  Features: [  6.6   0.7 200.   18.  180.   23.  200.   65.    0.6   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "   1.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.    0.    0.    0.    0. ]\n",
      "  Actual Crop: 0\n",
      "  Predicted Crop: 0\n",
      "----------------------------------------\n",
      "Sample 6:\n",
      "  Features: [  6.6    0.7  200.    18.   180.    29.   600.    78.     0.75   0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     1.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     1.     0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     1.     0.     0.     0.     0.     0.     0.  ]\n",
      "  Actual Crop: 5\n",
      "  Predicted Crop: 5\n",
      "----------------------------------------\n",
      "Sample 7:\n",
      "  Features: [  6.2   0.5 150.   12.  140.   23.  200.   65.    0.6   0.    0.    0.\n",
      "   1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "   0.    1.    1.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
      "  Actual Crop: 0\n",
      "  Predicted Crop: 0\n",
      "----------------------------------------\n",
      "Sample 8:\n",
      "  Features: [  6.6    0.7  200.    18.   180.    29.   600.    78.     0.75   1.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     1.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     1.     0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     1.     0.     0.  ]\n",
      "  Actual Crop: 5\n",
      "  Predicted Crop: 5\n",
      "----------------------------------------\n",
      "Sample 9:\n",
      "  Features: [  6.6    0.7  200.    18.   180.    29.   600.    78.     0.75   0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     1.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     1.     0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     1.  ]\n",
      "  Actual Crop: 5\n",
      "  Predicted Crop: 5\n",
      "----------------------------------------\n",
      "Sample 10:\n",
      "  Features: [  7.4   0.8 220.   18.  260.   29.  600.   78.    0.7   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    1.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.    0.    0.    0. ]\n",
      "  Actual Crop: 2\n",
      "  Predicted Crop: 2\n",
      "----------------------------------------\n",
      "Accuracy on random 10 samples: 100.00% ✅\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick 10 random rows from dataset\n",
    "sample_indices = random.sample(range(len(X_train)), 10)\n",
    "sample_features = X_train[sample_indices]\n",
    "sample_labels = y_train[sample_indices]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(sample_features)\n",
    "\n",
    "print(\"\\n=== RANDOM SAMPLE TESTING ===\")\n",
    "for i in range(len(sample_indices)):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Features: {sample_features[i]}\")\n",
    "    print(f\"  Actual Crop: {sample_labels[i]}\")\n",
    "    print(f\"  Predicted Crop: {predictions[i]}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Accuracy on these 10 random samples\n",
    "sample_accuracy = sum(predictions == sample_labels) / len(sample_labels)\n",
    "print(f\"Accuracy on random 10 samples: {sample_accuracy*100:.2f}% ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d31988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Imports ready.\n",
      "[Step 1] Dataset loaded: shape=(18240, 21)\n",
      "Columns: ['Year', 'District', 'Mandal', 'Season', 'Soil_Type', 'Soil_pH', 'Organic_Carbon_pct', 'Soil_N_kg_ha', 'Soil_P_kg_ha', 'Soil_K_kg_ha', 'Avg_Temp_C', 'Seasonal_Rainfall_mm', 'Avg_Humidity_pct', 'Water_Source', 'Previous_Crop', 'Primary_Crop', 'Secondary_Crop', 'Suitable_Crops', 'Fertilizer_Plan', 'Irrigation_Plan', 'Market_Price_Index']\n",
      "[Step 2] Crops detected: 14 -> ['Bengal Gram', 'Chillies', 'Cotton', 'Green Gram', 'Groundnut', 'Maize', 'Millets', 'Paddy', 'Pearl Millet', 'Sesame', 'Sorghum', 'Sunflower', 'Vegetables', 'Watermelon']\n",
      "[Step 3] Missing numeric values imputed (district-season aware).\n",
      "[Step 4] Features prepared: X=(18240, 669), y=(18240,), classes=8\n",
      "Epoch 20/200 | Loss: 1.4867\n",
      "Epoch 40/200 | Loss: 0.6507\n",
      "Epoch 60/200 | Loss: 0.3071\n",
      "Epoch 80/200 | Loss: 0.1237\n",
      "Epoch 100/200 | Loss: 0.0630\n",
      "Epoch 120/200 | Loss: 0.0392\n",
      "Epoch 140/200 | Loss: 0.0274\n",
      "Epoch 160/200 | Loss: 0.0207\n",
      "Epoch 180/200 | Loss: 0.0164\n",
      "Epoch 200/200 | Loss: 0.0135\n",
      "[Step 5] Model trained (Simple MLP from scratch) ✅\n",
      "[Step 6] Holdout 20% → Acc=1.000 | Macro-F1=1.000 | Top-3 Hit=1.000\n",
      "Epoch 10/50 | Loss: 1.8802\n",
      "Epoch 20/50 | Loss: 1.4994\n",
      "Epoch 30/50 | Loss: 0.9587\n",
      "Epoch 40/50 | Loss: 0.6902\n",
      "Epoch 50/50 | Loss: 0.4955\n",
      "Epoch 10/50 | Loss: 1.8789\n",
      "Epoch 20/50 | Loss: 1.4889\n",
      "Epoch 30/50 | Loss: 0.9542\n",
      "Epoch 40/50 | Loss: 0.6477\n",
      "Epoch 50/50 | Loss: 0.4456\n",
      "Epoch 10/50 | Loss: 1.8802\n",
      "Epoch 20/50 | Loss: 1.4962\n",
      "Epoch 30/50 | Loss: 0.9592\n",
      "Epoch 40/50 | Loss: 0.6686\n",
      "Epoch 50/50 | Loss: 0.4777\n",
      "Epoch 10/50 | Loss: 1.8803\n",
      "Epoch 20/50 | Loss: 1.4883\n",
      "Epoch 30/50 | Loss: 0.9292\n",
      "Epoch 40/50 | Loss: 0.6339\n",
      "Epoch 50/50 | Loss: 0.4267\n",
      "Epoch 10/50 | Loss: 1.8746\n",
      "Epoch 20/50 | Loss: 1.4931\n",
      "Epoch 30/50 | Loss: 0.9623\n",
      "Epoch 40/50 | Loss: 0.6655\n",
      "Epoch 50/50 | Loss: 0.4766\n",
      "[Step 6] 5-fold CV → Acc=0.838 | Macro-F1=0.559 | Top-3 Hit=1.000\n",
      "[Step 7] Saved → croprecommender_mlp.npz, encoders.pkl, feature_cols.json ✅\n",
      "\n",
      "[Step 10] Demo: NO soil test input →\n",
      "  - Paddy: 0.953\n",
      "    • Daily flooding, maintain 5–10 cm standing water.\n",
      "    • Ensure water at tillering and flowering.\n",
      "  - Groundnut: 0.024\n",
      "    • Irrigate ~every 10 days.\n",
      "    • Critical: flowering & pegging stages.\n",
      "  - Cotton: 0.021\n",
      "    • Irrigate ~every 15 days; adjust by weather.\n",
      "    • Critical: squaring, flowering, boll formation.\n",
      "\n",
      "[Step 10] Demo: WITH soil test input →\n",
      "  - Paddy: 0.589\n",
      "    • Daily flooding, maintain 5–10 cm standing water.\n",
      "    • Ensure water at tillering and flowering.\n",
      "  - Bengal Gram: 0.385\n",
      "    • Minimal irrigation; drought-tolerant.\n",
      "    • One light irrigation at flowering if very dry.\n",
      "  - Chillies: 0.012\n",
      "    • Follow crop-specific schedule.\n",
      "\n",
      "[Step 11] Testing on 10 random samples from the test set:\n",
      "  Sample 1: Predicted 'Paddy', Actual 'Paddy' (✅ Correct)\n",
      "  Sample 2: Predicted 'Paddy', Actual 'Paddy' (✅ Correct)\n",
      "  Sample 3: Predicted 'Vegetables', Actual 'Vegetables' (✅ Correct)\n",
      "  Sample 4: Predicted 'Pearl Millet', Actual 'Pearl Millet' (✅ Correct)\n",
      "  Sample 5: Predicted 'Groundnut', Actual 'Groundnut' (✅ Correct)\n",
      "  Sample 6: Predicted 'Vegetables', Actual 'Vegetables' (✅ Correct)\n",
      "  Sample 7: Predicted 'Vegetables', Actual 'Vegetables' (✅ Correct)\n",
      "  Sample 8: Predicted 'Pearl Millet', Actual 'Pearl Millet' (✅ Correct)\n",
      "  Sample 9: Predicted 'Pearl Millet', Actual 'Pearl Millet' (✅ Correct)\n",
      "  Sample 10: Predicted 'Paddy', Actual 'Paddy' (✅ Correct)\n",
      "\n",
      "Accuracy for this random batch of 10 samples: 100.00%\n",
      "\n",
      "✅ DONE: training → evaluation → saved model → deploy helpers ready.\n"
     ]
    }
   ],
   "source": [
    "import json, ast, math, os, random, pickle\n",
    "from collections import defaultdict, Counter\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "CSV_PATH = \"apcrop_dataset_realistic.csv\" # <-- your file\n",
    "\n",
    "print(\"[Step 0] Imports ready.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# small helpers\n",
    "# ------------------------------------------------------------\n",
    "def try_parse_list(x):\n",
    "    \"\"\"Parse '[\"Paddy\",\"Groundnut\"]' safely into list[str].\"\"\"\n",
    "    if pd.isna(x): return []\n",
    "    if isinstance(x, list): return [str(i).strip() for i in x]\n",
    "    s = str(x).strip()\n",
    "    if not s: return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list): \n",
    "            return [str(i).strip() for i in v]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback: split by comma\n",
    "    s = s.replace(\"[\",\"\").replace(\"]\",\"\").replace('\"','').replace(\"'\",\"\")\n",
    "    return [t.strip() for t in s.split(\",\") if t.strip()]\n",
    "\n",
    "def try_parse_json(x):\n",
    "    if pd.isna(x): return {}\n",
    "    s = str(x).strip()\n",
    "    if not s: return {}\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "def nanmean_safe(series, fallback=None):\n",
    "    v = pd.to_numeric(series, errors=\"coerce\")\n",
    "    m = v.mean()\n",
    "    if pd.isna(m):\n",
    "        return fallback\n",
    "    return m\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) LOAD\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"[Step 1] Dataset loaded: shape={df.shape}\")\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) BASIC NORMALIZATION / PARSE TARGETS\n",
    "# ------------------------------------------------------------\n",
    "expected_cols = [\n",
    "    \"Year\",\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\n",
    "    \"Soil_pH\",\"Organic_Carbon_pct\",\"Soil_N_kg_ha\",\"Soil_P_kg_ha\",\"Soil_K_kg_ha\",\n",
    "    \"Avg_Temp_C\",\"Seasonal_Rainfall_mm\",\"Avg_Humidity_pct\",\n",
    "    \"Water_Source\",\"Previous_Crop\",\"Primary_Crop\",\"Secondary_Crop\",\n",
    "    \"Suitable_Crops\",\"Fertilizer_Plan\",\"Irrigation_Plan\",\"Market_Price_Index\"\n",
    "]\n",
    "for col in expected_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan # create missing columns\n",
    "\n",
    "# ensure text columns are strings\n",
    "for c in [\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\"Water_Source\",\"Previous_Crop\",\"Primary_Crop\",\"Secondary_Crop\"]:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# parse multi-label and plans\n",
    "df[\"Suitable_Crops_List\"] = df[\"Suitable_Crops\"].apply(try_parse_list)\n",
    "df[\"FertJSON\"] = df[\"Fertilizer_Plan\"].apply(try_parse_json)\n",
    "df[\"IrrJSON\"]  = df[\"Irrigation_Plan\"].apply(try_parse_json)\n",
    "\n",
    "# collect all unique crop names visible in dataset\n",
    "crop_set = set()\n",
    "for col in [\"Primary_Crop\",\"Secondary_Crop\"]:\n",
    "    crop_set.update(df[col].dropna().astype(str).str.strip())\n",
    "for L in df[\"Suitable_Crops_List\"]:\n",
    "    crop_set.update(L)\n",
    "# clean empties\n",
    "crop_set = {c for c in crop_set if c and c.lower()!=\"nan\"}\n",
    "crop_list = sorted(crop_set)\n",
    "print(f\"[Step 2] Crops detected: {len(crop_list)} -> {crop_list}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) IMPUTATION VALUES (District+Season aware)\n",
    "# ------------------------------------------------------------\n",
    "num_cols = [\"Soil_pH\",\"Organic_Carbon_pct\",\"Soil_N_kg_ha\",\"Soil_P_kg_ha\",\"Soil_K_kg_ha\",\n",
    "            \"Avg_Temp_C\",\"Seasonal_Rainfall_mm\",\"Avg_Humidity_pct\",\"Market_Price_Index\"]\n",
    "\n",
    "# seasonal defaults if whole column empty\n",
    "season_defaults = {\n",
    "    \"Kharif\": {\"Avg_Temp_C\": 29.0, \"Seasonal_Rainfall_mm\": 600.0, \"Avg_Humidity_pct\": 78.0},\n",
    "    \"Rabi\":   {\"Avg_Temp_C\": 23.0, \"Seasonal_Rainfall_mm\": 200.0, \"Avg_Humidity_pct\": 65.0},\n",
    "    \"Zaid\":   {\"Avg_Temp_C\": 31.0, \"Seasonal_Rainfall_mm\": 120.0, \"Avg_Humidity_pct\": 70.0},\n",
    "}\n",
    "\n",
    "# compute district-season means\n",
    "group_means = df.groupby([\"District\",\"Season\"])[num_cols].agg(lambda s: pd.to_numeric(s, errors=\"coerce\").mean()).reset_index()\n",
    "\n",
    "def impute_row(row):\n",
    "    d, s = row[\"District\"], row[\"Season\"]\n",
    "    # lookup district-season row\n",
    "    g = group_means[(group_means[\"District\"]==d) & (group_means[\"Season\"]==s)]\n",
    "    for col in num_cols:\n",
    "        if pd.isna(row[col]) or str(row[col]).strip()==\"\":\n",
    "            # district-season mean -> season default -> global mean\n",
    "            val = None\n",
    "            if not g.empty and not pd.isna(g.iloc[0][col]):\n",
    "                val = g.iloc[0][col]\n",
    "            if val is None or pd.isna(val):\n",
    "                if s in season_defaults and col in season_defaults[s]:\n",
    "                    val = season_defaults[s][col]\n",
    "            if val is None or pd.isna(val):\n",
    "                val = nanmean_safe(df[col], 0.0)\n",
    "            row[col] = val\n",
    "    return row\n",
    "\n",
    "df = df.apply(impute_row, axis=1)\n",
    "print(\"[Step 3] Missing numeric values imputed (district-season aware).\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) FEATURE ENGINEERING\n",
    "#     - encode categoricals with a custom OneHot encoder\n",
    "#     - scale numeric features with a custom StandardScaler\n",
    "# ------------------------------------------------------------\n",
    "cat_cols = [\"District\",\"Mandal\",\"Season\",\"Soil_Type\",\"Water_Source\",\"Previous_Crop\"]\n",
    "target_col = \"Primary_Crop\" # single-label target for training\n",
    "\n",
    "# Custom One-Hot Encoder\n",
    "class OneHotEncoderLite:\n",
    "    def __init__(self):\n",
    "        self.cat_maps = {}  # col -> {category: index}\n",
    "        self.col_index_ranges = {}  # col -> (start,end)\n",
    "        self.n_features_ = 0\n",
    "    \n",
    "    def fit(self, frame, cat_cols):\n",
    "        start = 0\n",
    "        for col in cat_cols:\n",
    "            uniq = sorted({str(x) for x in frame[col].fillna(\"NA_VALUE\").astype(str)})\n",
    "            mapping = {u:i for i,u in enumerate(uniq)}\n",
    "            self.cat_maps[col] = mapping\n",
    "            end = start + len(mapping)\n",
    "            self.col_index_ranges[col] = (start, end)\n",
    "            start = end\n",
    "        self.n_features_ = start\n",
    "        return self\n",
    "    \n",
    "    def transform(self, frame):\n",
    "        # build empty array: (n_samples, total_cat_dim)\n",
    "        out = np.zeros((len(frame), self.n_features_), dtype=np.float32)\n",
    "        for col, mapping in self.cat_maps.items():\n",
    "            start, end = self.col_index_ranges[col]\n",
    "            idxs = frame[col].fillna(\"NA_VALUE\").astype(str).map(lambda v: mapping.get(v, None))\n",
    "            for i, idx in enumerate(idxs):\n",
    "                if idx is not None:\n",
    "                    out[i, start+idx] = 1.0\n",
    "        return out\n",
    "\n",
    "# Custom Standard Scaler for numeric features\n",
    "class StandardScalerLite:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        X = X.astype(float)\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.scale_ = np.std(X, axis=0)\n",
    "        # Avoid division by zero for constant features\n",
    "        self.scale_[self.scale_ == 0] = 1.0\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.astype(float)\n",
    "        return (X - self.mean_) / self.scale_\n",
    "\n",
    "# prepare numeric matrix\n",
    "X_num_raw = df[num_cols].astype(float).values.astype(np.float32)\n",
    "\n",
    "# fit and transform numeric data\n",
    "scaler = StandardScalerLite().fit(X_num_raw)\n",
    "X_num = scaler.transform(X_num_raw)\n",
    "\n",
    "# fit and transform categorical data\n",
    "ohe = OneHotEncoderLite().fit(df, cat_cols)\n",
    "X_cat = ohe.transform(df)\n",
    "\n",
    "# final features = [scaled numeric | onehot]\n",
    "X = np.concatenate([X_num, X_cat], axis=1)\n",
    "\n",
    "# target encode to integers\n",
    "class LabelEncoderLite:\n",
    "    def __init__(self):\n",
    "        self.class_to_id = {}\n",
    "        self.id_to_class = []\n",
    "    def fit(self, y):\n",
    "        uniq = sorted(set(y))\n",
    "        self.class_to_id = {c:i for i,c in enumerate(uniq)}\n",
    "        self.id_to_class = uniq\n",
    "        return self\n",
    "    def transform(self, y):\n",
    "        return np.array([self.class_to_id[v] for v in y], dtype=np.int64)\n",
    "    def inverse_transform(self, ids):\n",
    "        return [self.id_to_class[i] for i in ids]\n",
    "\n",
    "le_y = LabelEncoderLite().fit(df[target_col].astype(str))\n",
    "y = le_y.transform(df[target_col].astype(str))\n",
    "\n",
    "print(f\"[Step 4] Features prepared: X={X.shape}, y={y.shape}, classes={len(le_y.id_to_class)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) MODEL (from scratch SimpleMLP)\n",
    "# ------------------------------------------------------------\n",
    "# Activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0) * 1\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Loss function\n",
    "def cross_entropy_loss(y_true_onehot, y_pred_proba):\n",
    "    m = y_true_onehot.shape[0]\n",
    "    log_probs = -np.log(np.clip(y_pred_proba, 1e-12, 1.0))\n",
    "    loss = np.sum(y_true_onehot * log_probs) / m\n",
    "    return loss\n",
    "\n",
    "class SimpleMLP:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=0.001, epochs=200, batch_size=64, log_interval=20):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.log_interval = log_interval\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_dim, self.hidden_dim) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_dim))\n",
    "        self.W2 = np.random.randn(self.hidden_dim, self.output_dim) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_dim))\n",
    "\n",
    "    def _to_one_hot(self, y):\n",
    "        one_hot = np.zeros((len(y), self.output_dim))\n",
    "        one_hot[np.arange(len(y)), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def _forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        m = len(X_train)\n",
    "        y_one_hot = self._to_one_hot(y_train)\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            # Shuffle data for each epoch\n",
    "            indices = np.random.permutation(m)\n",
    "            X_shuffled = X_train[indices]\n",
    "            y_one_hot_shuffled = y_one_hot[indices]\n",
    "            \n",
    "            for i in range(0, m, self.batch_size):\n",
    "                X_batch = X_shuffled[i:i + self.batch_size]\n",
    "                y_batch = y_one_hot_shuffled[i:i + self.batch_size]\n",
    "                \n",
    "                if len(X_batch) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred_proba = self._forward(X_batch)\n",
    "                \n",
    "                # Backpropagation\n",
    "                # Output layer\n",
    "                dz2 = y_pred_proba - y_batch\n",
    "                dW2 = np.dot(self.a1.T, dz2) / len(X_batch)\n",
    "                db2 = np.sum(dz2, axis=0, keepdims=True) / len(X_batch)\n",
    "\n",
    "                # Hidden layer\n",
    "                dz1 = np.dot(dz2, self.W2.T) * relu_derivative(self.z1)\n",
    "                dW1 = np.dot(X_batch.T, dz1) / len(X_batch)\n",
    "                db1 = np.sum(dz1, axis=0, keepdims=True) / len(X_batch)\n",
    "                \n",
    "                # Update weights\n",
    "                self.W1 -= self.lr * dW1\n",
    "                self.b1 -= self.lr * db1\n",
    "                self.W2 -= self.lr * dW2\n",
    "                self.b2 -= self.lr * db2\n",
    "\n",
    "            if epoch % self.log_interval == 0:\n",
    "                y_pred_proba_full = self._forward(X_train)\n",
    "                loss = cross_entropy_loss(y_one_hot, y_pred_proba_full)\n",
    "                print(f\"Epoch {epoch}/{self.epochs} | Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self._forward(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "# split (holdout) — we’ll also do 5-fold CV later\n",
    "idx = np.arange(len(df))\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.8*len(idx))\n",
    "train_idx, test_idx = idx[:split], idx[split:]\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test,  y_test  = X[test_idx],  y[test_idx]\n",
    "\n",
    "model = SimpleMLP(input_dim=X.shape[1], hidden_dim=128, output_dim=len(le_y.id_to_class), lr=0.001, epochs=200, batch_size=64, log_interval=20)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"[Step 5] Model trained (Simple MLP from scratch) ✅\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) EVALUATION\n",
    "# ------------------------------------------------------------\n",
    "def metrics_basic(y_true, y_pred, proba=None, top_k=3):\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    # macro precision/recall/f1\n",
    "    K = len(set(y_true) | set(y_pred))\n",
    "    precs, recs, f1s = [], [], []\n",
    "    for k in range(K):\n",
    "        tp = np.sum((y_true==k) & (y_pred==k))\n",
    "        fp = np.sum((y_true!=k) & (y_pred==k))\n",
    "        fn = np.sum((y_true==k) & (y_pred!=k))\n",
    "        precision = tp / (tp+fp) if (tp+fp)>0 else 0.0\n",
    "        recall    = tp / (tp+fn) if (tp+fn)>0 else 0.0\n",
    "        f1 = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0.0\n",
    "        precs.append(precision); recs.append(recall); f1s.append(f1)\n",
    "    macro_p, macro_r, macro_f1 = np.mean(precs), np.mean(recs), np.mean(f1s)\n",
    "\n",
    "    topk = None\n",
    "    if proba is not None:\n",
    "        topk_preds = np.argsort(-proba, axis=1)[:, :top_k]\n",
    "        hits = [(y_true[i] in topk_preds[i]) for i in range(len(y_true))]\n",
    "        topk = np.mean(hits)\n",
    "    return acc, macro_p, macro_r, macro_f1, topk\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "proba_test  = model.predict_proba(X_test)\n",
    "acc, mp, mr, mf1, top3 = metrics_basic(y_test, y_pred_test, proba_test, top_k=3)\n",
    "print(f\"[Step 6] Holdout 20% → Acc={acc:.3f} | Macro-F1={mf1:.3f} | Top-3 Hit={top3:.3f}\")\n",
    "\n",
    "# 5-fold CV for robustness\n",
    "def kfold_eval(X, y, k=5):\n",
    "    N = len(y)\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "    folds = np.array_split(idx, k)\n",
    "    accs, f1s, top3s = [], [], []\n",
    "    for i in range(k):\n",
    "        test_i = folds[i]\n",
    "        train_i = np.hstack([folds[j] for j in range(k) if j!=i])\n",
    "        m = SimpleMLP(input_dim=X.shape[1], hidden_dim=128, output_dim=len(le_y.id_to_class), lr=0.001, epochs=50, batch_size=64, log_interval=10)\n",
    "        m.fit(X[train_i], y[train_i])\n",
    "        yp = m.predict(X[test_i])\n",
    "        pp = m.predict_proba(X[test_i])\n",
    "        a,_,_,f1,t3 = metrics_basic(y[test_i], yp, pp, top_k=3)\n",
    "        accs.append(a); f1s.append(f1); top3s.append(t3)\n",
    "    return np.mean(accs), np.mean(f1s), np.mean(top3s)\n",
    "\n",
    "cv_acc, cv_f1, cv_top3 = kfold_eval(X, y, k=5)\n",
    "print(f\"[Step 6] 5-fold CV → Acc={cv_acc:.3f} | Macro-F1={cv_f1:.3f} | Top-3 Hit={cv_top3:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) SAVE ARTIFACTS\n",
    "# ------------------------------------------------------------\n",
    "ART_DIR = \".\"\n",
    "np.savez(os.path.join(ART_DIR,\"croprecommender_mlp.npz\"),\n",
    "         W1=model.W1, b1=model.b1, W2=model.W2, b2=model.b2)\n",
    "\n",
    "with open(os.path.join(ART_DIR,\"encoders.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\"ohe\":ohe, \"le_y\":le_y, \"num_cols\":num_cols, \"cat_cols\":cat_cols, \"scaler\":scaler}, f)\n",
    "\n",
    "with open(os.path.join(ART_DIR,\"feature_cols.json\"), \"w\") as f:\n",
    "    json.dump({\"num_cols\":num_cols, \"cat_cols\":cat_cols}, f, indent=2)\n",
    "\n",
    "print(\"[Step 7] Saved → croprecommender_mlp.npz, encoders.pkl, feature_cols.json ✅\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) IRRIGATION SUGGESTIONS (your mapping)\n",
    "# ------------------------------------------------------------\n",
    "IRRIGATION_TIPS = {\n",
    "    \"Paddy\": [\n",
    "        \"Daily flooding, maintain 5–10 cm standing water.\",\n",
    "        \"Ensure water at tillering and flowering.\",\n",
    "        \"Drain completely 7–10 days before harvest.\"\n",
    "    ],\n",
    "    \"Maize\": [\n",
    "        \"Irrigate weekly; adjust to rainfall & soil.\",\n",
    "        \"Critical: tasseling, silking, grain filling.\",\n",
    "        \"Avoid stress in reproductive phase.\"\n",
    "    ],\n",
    "    \"Groundnut\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: flowering & pegging stages.\",\n",
    "        \"Keep moisture during pod development.\"\n",
    "    ],\n",
    "    \"Wheat\": [\n",
    "        \"Irrigate at CRI, jointing, flowering.\",\n",
    "        \"CRI (≈21 DAS) is most critical.\",\n",
    "        \"Avoid waterlogging.\"\n",
    "    ],\n",
    "    \"Bengal Gram\": [\n",
    "        \"Minimal irrigation; drought-tolerant.\",\n",
    "        \"One light irrigation at flowering if very dry.\",\n",
    "        \"Avoid heavy irrigation.\"\n",
    "    ],\n",
    "    \"Sunflower\": [\n",
    "        \"Irrigate ~every 12 days.\",\n",
    "        \"Critical: bud, flowering, seed filling.\",\n",
    "        \"Drip works very well.\"\n",
    "    ],\n",
    "    \"Castor\": [\n",
    "        \"Irrigate ~every 15 days.\",\n",
    "        \"Provide at branching & spike initiation.\",\n",
    "        \"Too much water → foliage, fewer seeds.\"\n",
    "    ],\n",
    "    \"Bajra\": [\n",
    "        \"Prefer rainfed; drought-tolerant.\",\n",
    "        \"If needed, irrigate at flowering & grain filling.\",\n",
    "        \"Avoid over-irrigation (lodging risk).\"\n",
    "    ],\n",
    "    \"Linseed\": [\n",
    "        \"Light irrigation at branching & flowering.\",\n",
    "        \"Never waterlog; highly susceptible.\",\n",
    "        \"1–2 irrigations often enough.\"\n",
    "    ],\n",
    "    \"Mustard\": [\n",
    "        \"Irrigate at branching & pod filling.\",\n",
    "        \"First irrigation 30–35 DAS.\",\n",
    "        \"Avoid watering during flowering.\"\n",
    "    ],\n",
    "    \"Watermelon\": [\n",
    "        \"Irrigate ~every 7 days; keep moisture even.\",\n",
    "        \"Avoid stress at flowering & fruit set.\",\n",
    "        \"Reduce water near maturity for sweetness.\"\n",
    "    ],\n",
    "    \"Muskmelon\": [\n",
    "        \"Irrigate ~every 7 days, avoid waterlogging.\",\n",
    "        \"Consistent water for fruit growth & quality.\",\n",
    "        \"Drip reduces fungal risk.\"\n",
    "    ],\n",
    "    \"Cowpea\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: flowering & pod development.\",\n",
    "        \"Drought tolerant but timely water boosts yield.\"\n",
    "    ],\n",
    "    \"Cotton\": [\n",
    "        \"Irrigate ~every 15 days; adjust by weather.\",\n",
    "        \"Critical: squaring, flowering, boll formation.\",\n",
    "        \"Avoid waterlogging (boll rot).\"\n",
    "    ],\n",
    "    \"Sugarcane\": [\n",
    "        \"Frequent water in hot/dry months.\",\n",
    "        \"Formative stage (to ~120 DAS) needs moisture.\",\n",
    "        \"Reduce 1–2 months pre-harvest.\"\n",
    "    ],\n",
    "    \"Barley\": [\n",
    "        \"Light irrigations as needed.\",\n",
    "        \"CRI is most crucial.\",\n",
    "        \"Sensitive to waterlogging.\"\n",
    "    ],\n",
    "    \"Lentil\": [\n",
    "        \"Mostly rainfed.\",\n",
    "        \"One light irrigation pre-flowering may help.\",\n",
    "        \"Too much water → vegetative growth.\"\n",
    "    ],\n",
    "    \"Soybean\": [\n",
    "        \"Prefer rainfed/moderate drought tolerance.\",\n",
    "        \"Supplement at pod filling if dry.\",\n",
    "        \"Avoid irrigation during flowering.\"\n",
    "    ],\n",
    "    \"Pea\": [\n",
    "        \"Irrigate at flowering & pod filling.\",\n",
    "        \"Initial irrigation helps germination.\",\n",
    "        \"Avoid overwatering (root rot risk).\"\n",
    "    ],\n",
    "    \"Vegetables\": [\n",
    "        \"Irrigate every 5–7 days depending on crop.\",\n",
    "        \"Drip to root-zone conserves water.\",\n",
    "        \"Consistency prevents cracking/bitterness.\"\n",
    "    ],\n",
    "    \"Jute\": [\n",
    "        \"Keep soil moist throughout.\",\n",
    "        \"Frequent light irrigation in hot season.\",\n",
    "        \"Ensure drainage to avoid root decay.\"\n",
    "    ],\n",
    "    \"Oats\": [\n",
    "        \"Irrigate ~every 12 days.\",\n",
    "        \"Critical: tillering & flowering.\",\n",
    "        \"Relatively drought-tolerant.\"\n",
    "    ],\n",
    "    \"Cucumber\": [\n",
    "        \"Irrigate ~every 7 days; uniform moisture.\",\n",
    "        \"Consistent water at fruit set & growth.\",\n",
    "        \"Low water → bitter fruits.\"\n",
    "    ],\n",
    "    \"Sugar Beet\": [\n",
    "        \"Irrigate ~every 10 days.\",\n",
    "        \"Critical: canopy establishment, root bulking.\",\n",
    "        \"Avoid waterlogging (low sugar, root rot).\"\n",
    "    ],\n",
    "    \"Pearl Millet\": [\n",
    "        \"Prefer rainfed; very drought-tolerant.\",\n",
    "        \"If needed, irrigate at flowering.\",\n",
    "        \"Water stress at grain filling cuts yield.\"\n",
    "    ],\n",
    "    \"Cluster Bean\": [\n",
    "        \"Prefer rainfed; arid-suited.\",\n",
    "        \"1–2 light irrigations in long dry spells.\",\n",
    "        \"Overwatering reduces pod set.\"\n",
    "    ],\n",
    "    \"Sesame\": [\n",
    "        \"Prefer rainfed; drought-hardy.\",\n",
    "        \"One irrigation at flowering if dry.\",\n",
    "        \"Avoid waterlogging (root rot).\"\n",
    "    ],\n",
    "    \"Green Gram\": [\n",
    "        \"Rainfed OK; one irrigation at flowering.\",\n",
    "        \"Avoid heavy irrigation (root disease risk).\",\n",
    "        \"Irrigation can boost yield modestly.\"\n",
    "    ],\n",
    "    \"Millets\": [\n",
    "        \"Mostly rainfed; high drought tolerance.\",\n",
    "        \"Irrigate only at critical stages if very dry.\",\n",
    "        \"Avoid excessive water.\"\n",
    "    ],\n",
    "    \"Sorghum\": [\n",
    "        \"Mostly rainfed; irrigate if prolonged dry.\",\n",
    "        \"Critical: booting & flowering.\",\n",
    "        \"Avoid waterlogging.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) DEPLOYMENT HELPERS\n",
    "# ------------------------------------------------------------\n",
    "def build_feature_row(input_dict, ohe, num_cols, cat_cols, scaler):\n",
    "    \"\"\"\n",
    "    input_dict keys may include numeric and categorical fields.\n",
    "    Missing numeric are imputed with district-season means (computed earlier) or season defaults.\n",
    "    \"\"\"\n",
    "    # Start with a template row\n",
    "    row = {}\n",
    "    # numeric\n",
    "    for c in num_cols:\n",
    "        row[c] = input_dict.get(c, None)\n",
    "    # categorical\n",
    "    for c in cat_cols:\n",
    "        row[c] = input_dict.get(c, \"NA_VALUE\")\n",
    "\n",
    "    # impute numeric using same logic as training\n",
    "    tmp = pd.DataFrame([row])\n",
    "    # attach District & Season so imputer can work\n",
    "    tmp[\"District\"] = row.get(\"District\", \"NA_VALUE\")\n",
    "    tmp[\"Season\"]   = row.get(\"Season\",   \"Kharif\")\n",
    "\n",
    "    # district-season means lookup\n",
    "    g = group_means[(group_means[\"District\"]==tmp.at[0,\"District\"]) & (group_means[\"Season\"]==tmp.at[0,\"Season\"])]\n",
    "\n",
    "    for col in num_cols:\n",
    "        val = tmp.at[0, col]\n",
    "        if val is None or (isinstance(val,str) and not val.strip()):\n",
    "            # fill\n",
    "            dv = None\n",
    "            if not g.empty and not pd.isna(g.iloc[0][col]):\n",
    "                dv = g.iloc[0][col]\n",
    "            if (dv is None or pd.isna(dv)) and tmp.at[0,\"Season\"] in season_defaults and col in season_defaults[tmp.at[0,\"Season\"]]:\n",
    "                dv = season_defaults[tmp.at[0,\"Season\"]][col]\n",
    "            if dv is None or pd.isna(dv):\n",
    "                dv = nanmean_safe(df[col], 0.0)\n",
    "            tmp.at[0, col] = dv\n",
    "\n",
    "    # numeric block\n",
    "    x_num_raw = tmp[num_cols].astype(float).values.astype(np.float32)\n",
    "    x_num = scaler.transform(x_num_raw)\n",
    "    # categorical block via ohe\n",
    "    x_cat = ohe.transform(tmp[cat_cols])\n",
    "    # final vector\n",
    "    x = np.concatenate([x_num, x_cat], axis=1)\n",
    "    return x\n",
    "\n",
    "def predict_topN(input_dict, N=3):\n",
    "    x = build_feature_row(input_dict, ohe=ohe, num_cols=num_cols, cat_cols=cat_cols, scaler=scaler)\n",
    "    probs = model.predict_proba(x)[0]\n",
    "    top_idx = np.argsort(-probs)[:N]\n",
    "    crops = [le_y.id_to_class[i] for i in top_idx]\n",
    "    confs = [float(probs[i]) for i in top_idx]\n",
    "    tips  = {c: IRRIGATION_TIPS.get(c, [\"Follow crop-specific schedule.\"]) for c in crops}\n",
    "    return list(zip(crops, confs)), tips\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) QUICK DEMO PREDICTION (with/without soil test)\n",
    "#     “Soil test? No” → only district, season, water source are enough.\n",
    "# ------------------------------------------------------------\n",
    "demo_no_soil = {\n",
    "    \"District\": \"Srikakulam\",\n",
    "    \"Season\": \"Kharif\",\n",
    "    \"Water_Source\": \"Tank\",     # choose among: Tank/Canal/Borewell/...\n",
    "    # no soil fields given\n",
    "}\n",
    "demo_with_soil = {\n",
    "    \"District\": \"Srikakulam\",\n",
    "    \"Season\": \"Rabi\",\n",
    "    \"Water_Source\": \"Tank\",\n",
    "    \"Soil_pH\": 6.6,\n",
    "    \"Organic_Carbon_pct\": 0.7,\n",
    "    \"Soil_N_kg_ha\": 200,\n",
    "    \"Soil_P_kg_ha\": 18,\n",
    "    \"Soil_K_kg_ha\": 180,\n",
    "    \"Avg_Temp_C\": 23.0,\n",
    "    \"Seasonal_Rainfall_mm\": 650,\n",
    "    \"Avg_Humidity_pct\": 68,\n",
    "    \"Market_Price_Index\": 0.62\n",
    "}\n",
    "\n",
    "print(\"\\n[Step 10] Demo: NO soil test input →\")\n",
    "preds, tips = predict_topN(demo_no_soil, N=3)\n",
    "for c, p in preds:\n",
    "    print(f\"  - {c}: {p:.3f}\")\n",
    "    for t in tips[c][:2]:\n",
    "        print(\"    •\", t)\n",
    "\n",
    "print(\"\\n[Step 10] Demo: WITH soil test input →\")\n",
    "preds2, tips2 = predict_topN(demo_with_soil, N=3)\n",
    "for c, p in preds2:\n",
    "    print(f\"  - {c}: {p:.3f}\")\n",
    "    for t in tips2[c][:2]:\n",
    "        print(\"    •\", t)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 11) TEST ON RANDOM SAMPLES\n",
    "# ------------------------------------------------------------\n",
    "def test_random_samples(model, X_test, y_test, le_y, num_samples=10):\n",
    "    print(f\"\\n[Step 11] Testing on {num_samples} random samples from the test set:\")\n",
    "    \n",
    "    # Get random indices from the test set\n",
    "    test_indices = np.random.choice(len(y_test), num_samples, replace=False)\n",
    "    X_sample = X_test[test_indices]\n",
    "    y_true_sample = y_test[test_indices]\n",
    "    \n",
    "    # Predict on the random samples\n",
    "    y_pred_sample_idx = model.predict(X_sample)\n",
    "    \n",
    "    # Inverse transform to get crop names\n",
    "    y_true_crops = le_y.inverse_transform(y_true_sample)\n",
    "    y_pred_crops = le_y.inverse_transform(y_pred_sample_idx)\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    for i in range(num_samples):\n",
    "        is_correct = (y_true_crops[i] == y_pred_crops[i])\n",
    "        status = \"✅ Correct\" if is_correct else \"❌ Incorrect\"\n",
    "        print(f\"  Sample {i+1}: Predicted '{y_pred_crops[i]}', Actual '{y_true_crops[i]}' ({status})\")\n",
    "        if is_correct:\n",
    "            correct_predictions += 1\n",
    "            \n",
    "    accuracy = correct_predictions / num_samples\n",
    "    print(f\"\\nAccuracy for this random batch of {num_samples} samples: {accuracy:.2%}\")\n",
    "\n",
    "test_random_samples(model, X_test, y_test, le_y, num_samples=10)\n",
    "\n",
    "print(\"\\n✅ DONE: training → evaluation → saved model → deploy helpers ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Loads and preprocesses the dataset robustly.\"\"\"\n",
    "    logging.info(\"[Step 1] Loading dataset...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Remove columns not needed\n",
    "    exclude_cols = ['Year', 'Suitable_Crops', 'Fertilizer_Plan', 'Irrigation_Plan', \n",
    "                    'Market_Price_Index', 'Previous_Crop']\n",
    "    df = df.drop(columns=exclude_cols, errors='ignore')\n",
    "\n",
    "    # Check target column\n",
    "    if 'Primary_Crop' not in df.columns:\n",
    "        raise ValueError(\"❌ 'Primary_Crop' column is missing in the dataset!\")\n",
    "\n",
    "    X = df.drop(columns='Primary_Crop')\n",
    "    y = df['Primary_Crop']\n",
    "\n",
    "    # Numeric and categorical separation\n",
    "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Handle numeric missing values\n",
    "    X_num = X[numerical_cols].copy()\n",
    "\n",
    "    if not X_num.empty:\n",
    "        num_cols_with_na = X_num.columns[X_num.isnull().any()].tolist()\n",
    "\n",
    "        if num_cols_with_na:\n",
    "            # Drop fully empty numeric columns\n",
    "            fully_empty = [col for col in num_cols_with_na if X_num[col].isnull().all()]\n",
    "            if fully_empty:\n",
    "                logging.warning(f\"Dropping fully empty numeric columns: {fully_empty}\")\n",
    "                X_num.drop(columns=fully_empty, inplace=True)\n",
    "                num_cols_with_na = [c for c in num_cols_with_na if c not in fully_empty]\n",
    "\n",
    "            if num_cols_with_na:\n",
    "                logging.info(f\"[Step 2] Imputing numeric columns {num_cols_with_na} using KNNImputer...\")\n",
    "                imputer = KNNImputer(n_neighbors=5)\n",
    "                imputed_values = imputer.fit_transform(X_num[num_cols_with_na])\n",
    "                for i, col in enumerate(num_cols_with_na):\n",
    "                    X_num[col] = imputed_values[:, i]\n",
    "        else:\n",
    "            logging.info(\"[Step 2] No missing numeric values to impute.\")\n",
    "    else:\n",
    "        logging.warning(\"No numeric columns found in dataset!\")\n",
    "\n",
    "    # Handle categorical missing values\n",
    "    if categorical_cols:\n",
    "        X_cat = X[categorical_cols].copy()\n",
    "        for col in categorical_cols:\n",
    "            X_cat[col] = X_cat[col].fillna(\"Unknown\")\n",
    "        logging.info(\"[Step 3] One-hot encoding categorical features...\")\n",
    "        X_cat_encoded = pd.get_dummies(X_cat, columns=categorical_cols, drop_first=True)\n",
    "    else:\n",
    "        X_cat_encoded = pd.DataFrame()\n",
    "        logging.warning(\"No categorical columns found in dataset!\")\n",
    "\n",
    "    # Combine numeric + categorical\n",
    "    X_processed = pd.concat([X_num, X_cat_encoded], axis=1)\n",
    "    X_processed = X_processed.fillna(0)  # Final safety net for any stray NaNs\n",
    "\n",
    "    logging.info(f\"[Step 4] Final features: X={X_processed.shape}, y={y.shape}\")\n",
    "    return X_processed, y\n",
    "\n",
    "def filter_and_label_data(X, y, min_samples=100):\n",
    "    \"\"\"Removes underrepresented crops and encodes labels.\"\"\"\n",
    "    logging.info(\"[Step 5] Filtering crops by minimum sample count...\")\n",
    "    crop_counts = y.value_counts()\n",
    "    crops_to_keep = crop_counts[crop_counts >= min_samples].index\n",
    "\n",
    "    X_filtered = X[y.isin(crops_to_keep)]\n",
    "    y_filtered = y[y.isin(crops_to_keep)]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_filtered)\n",
    "\n",
    "    logging.info(f\"Crops kept: {list(crops_to_keep)}\")\n",
    "    logging.info(f\"Filtered dataset shape: X={X_filtered.shape}, y={len(y_encoded)}, classes={len(le.classes_)}\")\n",
    "    return X_filtered, y_encoded, le.classes_, list(X_filtered.columns)\n",
    "\n",
    "def train_model(X, y, num_classes, feature_cols):\n",
    "    \"\"\"Builds and trains the MLP model.\"\"\"\n",
    "    logging.info(\"[Step 6] Building MLP model...\")\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    logging.info(\"[Step 7] Training model...\")\n",
    "    model.fit(X, y, epochs=100, batch_size=32, verbose=1)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y, classes):\n",
    "    \"\"\"Evaluates model performance.\"\"\"\n",
    "    logging.info(\"[Step 8] Evaluating model...\")\n",
    "    ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, test_idx = next(ss.split(X, y))\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    top3_hits = sum(1 for i in range(len(y_test)) \n",
    "                    if y_test[i] in predictions[i].argsort()[-3:][::-1])\n",
    "    top3_acc = top3_hits / len(y_test)\n",
    "\n",
    "    logging.info(f\"Accuracy: {acc:.3f} | Macro-F1: {f1:.3f} | Top-3 Accuracy: {top3_acc:.3f}\")\n",
    "\n",
    "def save_model(model, classes, feature_cols):\n",
    "    \"\"\"Saves model and metadata.\"\"\"\n",
    "    logging.info(\"[Step 9] Saving model...\")\n",
    "    model.save('croprecommender_mlp.h5')\n",
    "    np.savez('croprecommender_mlp.npz', classes=classes, feature_cols=feature_cols)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_initial, y_initial = load_and_preprocess_data('apcrop_dataset_realistic.csv')\n",
    "    X_filtered, y_encoded, classes, feature_cols = filter_and_label_data(X_initial, y_initial)\n",
    "    model = train_model(X_filtered, y_encoded, len(classes), feature_cols)\n",
    "    evaluate_model(model, X_filtered, y_encoded, classes)\n",
    "    save_model(model, classes, feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4836e",
   "metadata": {},
   "source": [
    "2025-08-13 20:20:40,653 - INFO - [Step 7] Training model...\n",
    "Epoch 1/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.4036 - loss: 1.9554     \n",
    "Epoch 2/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8442 - loss: 0.4235  \n",
    "Epoch 3/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9619 - loss: 0.1219  \n",
    "Epoch 4/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9832 - loss: 0.0597  \n",
    "Epoch 5/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0348  \n",
    "Epoch 6/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0464  \n",
    "Epoch 7/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0284  \n",
    "Epoch 8/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0306  \n",
    "Epoch 9/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0231  \n",
    "Epoch 10/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0246  \n",
    "Epoch 11/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0207  \n",
    "Epoch 12/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0240  \n",
    "Epoch 13/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0310  \n",
    "Epoch 14/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0328  \n",
    "Epoch 15/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0266  \n",
    "Epoch 16/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0342  \n",
    "Epoch 17/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0338  \n",
    "Epoch 18/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0396  \n",
    "Epoch 19/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9880 - loss: 0.0346  \n",
    "Epoch 20/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9867 - loss: 0.0404  \n",
    "Epoch 21/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9878 - loss: 0.0375  \n",
    "Epoch 22/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0389  \n",
    "Epoch 23/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9856 - loss: 0.0413  \n",
    "Epoch 24/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0464  \n",
    "Epoch 25/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0365  \n",
    "Epoch 26/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0435      \n",
    "Epoch 27/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9856 - loss: 0.0435  \n",
    "Epoch 28/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0329  \n",
    "Epoch 29/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0281  \n",
    "Epoch 30/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0308  \n",
    "Epoch 31/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0299  \n",
    "Epoch 32/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0283  \n",
    "Epoch 33/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0293  \n",
    "Epoch 34/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0331  \n",
    "Epoch 35/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0364  \n",
    "Epoch 36/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0396  \n",
    "Epoch 37/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0286  \n",
    "Epoch 38/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0253  \n",
    "Epoch 39/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0327  \n",
    "Epoch 40/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0360  \n",
    "Epoch 41/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0287  \n",
    "Epoch 42/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0228  \n",
    "Epoch 43/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0185      \n",
    "Epoch 44/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0338  \n",
    "Epoch 45/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0362  \n",
    "Epoch 46/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0380  \n",
    "Epoch 47/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0300  \n",
    "Epoch 48/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0216  \n",
    "Epoch 49/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9832 - loss: 0.0514  \n",
    "Epoch 50/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0371  \n",
    "Epoch 51/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0332  \n",
    "Epoch 52/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0484  \n",
    "Epoch 53/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0349  \n",
    "Epoch 54/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0354  \n",
    "Epoch 55/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0360  \n",
    "Epoch 56/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0474      \n",
    "Epoch 57/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0309  \n",
    "Epoch 58/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0269  \n",
    "Epoch 59/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9878 - loss: 0.0364  \n",
    "Epoch 60/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0372  \n",
    "Epoch 61/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0308  \n",
    "Epoch 62/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0248  \n",
    "Epoch 63/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0404      \n",
    "Epoch 64/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0348  \n",
    "Epoch 65/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0332    \n",
    "Epoch 66/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0215  \n",
    "Epoch 67/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0335  \n",
    "Epoch 68/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9870 - loss: 0.0411      \n",
    "Epoch 69/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9833 - loss: 0.0506  \n",
    "Epoch 70/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0375  \n",
    "Epoch 71/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0417  \n",
    "Epoch 72/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0279  \n",
    "Epoch 73/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0423  \n",
    "Epoch 74/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0601  \n",
    "Epoch 75/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0436  \n",
    "Epoch 76/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0362  \n",
    "Epoch 77/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0342  \n",
    "Epoch 78/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0234  \n",
    "Epoch 79/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9860 - loss: 0.0428  \n",
    "Epoch 80/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9887 - loss: 0.0347  \n",
    "Epoch 81/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0296  \n",
    "Epoch 82/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0348  \n",
    "Epoch 83/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0297  \n",
    "Epoch 84/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9839 - loss: 0.0475  \n",
    "Epoch 85/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0380      \n",
    "Epoch 86/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0349  \n",
    "Epoch 87/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0426  \n",
    "Epoch 88/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0275  \n",
    "Epoch 89/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0270  \n",
    "Epoch 90/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0376  \n",
    "Epoch 91/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9839 - loss: 0.0474  \n",
    "Epoch 92/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0347  \n",
    "Epoch 93/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9867 - loss: 0.0411  \n",
    "Epoch 94/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0289  \n",
    "Epoch 95/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0292  \n",
    "Epoch 96/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9874 - loss: 0.0422  \n",
    "Epoch 97/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0315  \n",
    "Epoch 98/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0207  \n",
    "Epoch 99/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9870 - loss: 0.0430  \n",
    "Epoch 100/100\n",
    "570/570 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0221      \n",
    "2025-08-13 20:22:23,212 - INFO - [Step 8] Evaluating model...\n",
    "114/114 ━━━━━━━━━━━━━━━━━━━━ 0s 864us/step\n",
    "2025-08-13 20:22:23,490 - INFO - Accuracy: 1.000 | Macro-F1: 1.000 | Top-3 Accuracy: 1.000\n",
    "2025-08-13 20:22:23,492 - INFO - [Step 9] Saving model...\n",
    "2025-08-13 20:22:23,492 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
